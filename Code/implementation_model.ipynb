{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import random\n",
    "import torch\n",
    "import glob\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change disk directory\n",
    "base_path = Path(\"G:/Dissertation/\")\n",
    "if(Path().cwd() != Path(r\"G:\\Dissertation\")):\n",
    "    os.chdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data_paths\n",
    "# raw_data_path = Path(\"raw_data/Data examples/\")\n",
    "# raw_visibility_path = raw_data_path / Path(\"1_Visibility/\")\n",
    "# raw_quality_path = raw_data_path/ Path(\"2_Quality/\")\n",
    "dataset_path = Path('dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import split_data\n",
    "\n",
    "data_dir = Path(\"small_split/\")\n",
    "split_size = [0.8,0.1,0.1]\n",
    "\n",
    "#split_data(dataset_path, data_dir, split_size, num_img_class=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "#Create transform (in this case for the ResNet images are resized to 224x224 and transformed into Tensors)\n",
    "data_transform = transforms.Compose([\n",
    "  # Resize our images to 64x64\n",
    "  transforms.Resize(size=(224, 224)),\n",
    "  # Flip the images randomly on the horizontal (just to make it as independent from the position of the pipeline)\n",
    "  transforms.RandomHorizontalFlip(p=0.5),\n",
    "  transforms.RandomVerticalFlip(p=0.5),\n",
    "  # Turn the image into a torch.Tensor\n",
    "  transforms.ToTensor() \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import create_dataloaders\n",
    "\n",
    "#Paths criados pelo split_data\n",
    "train_dir = data_dir / Path('train/')\n",
    "validation_dir = data_dir / Path('validation/')\n",
    "test_dir = data_dir / Path('test/')\n",
    "\n",
    "BATCH_SIZE = 128 # in the ResNet is 128 but my GPU doesn't have enough memory for that\n",
    "\n",
    "train_dataloader, validation_dataloader, test_dataloader, class_names = create_dataloaders(train_dir,test_dir,validation_dir,data_transform, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a single image batch\n",
    "image_batch, label_batch = next(iter(train_dataloader))\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 16 11:31:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.01       Driver Version: 516.01       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   59C    P8     5W /  N/A |   2355MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     20316      C   ...oaor\\anaconda3\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5e7167e46d46d2879b5e306ba1417a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.7656 | train_acc: 0.6633 | validation_loss: 22.8928 | validation_acc: 0.2441\n",
      "Epoch: 2 | train_loss: 0.5743 | train_acc: 0.7340 | validation_loss: 4.9895 | validation_acc: 0.4707\n",
      "Epoch: 3 | train_loss: 0.5321 | train_acc: 0.7480 | validation_loss: 0.6341 | validation_acc: 0.7266\n",
      "Epoch: 4 | train_loss: 0.5002 | train_acc: 0.7735 | validation_loss: 1.2028 | validation_acc: 0.5996\n",
      "Epoch: 5 | train_loss: 0.4532 | train_acc: 0.7965 | validation_loss: 6.5499 | validation_acc: 0.3965\n",
      "Total training time: 863.439 seconds\n"
     ]
    }
   ],
   "source": [
    "from engine import train\n",
    "from ResNet50 import ResNet50\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "model_1 = ResNet50().to(device)\n",
    "\n",
    "# Setup loss function and optimizer \n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(),\n",
    "                             lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer() \n",
    "\n",
    "# Train model\n",
    "model_results = train(model=model_1,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    validation_dataloader=validation_dataloader,\n",
    "                    optimizer=optimizer,\n",
    "                    loss_fn=loss_fn,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    device=device)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model to: Models\\ResNet50_1000_class_5_epoch.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import save_model, eval_model, accuracy_fn\n",
    "\n",
    "models_path = Path('Models/')\n",
    "model_name = 'ResNet50_1000_class_5_epoch.pth'\n",
    "\n",
    "save_model(models_path, model_name, model_1)\n",
    "\n",
    "\n",
    "model_path = models_path / model_name\n",
    "loaded_model = ResNet50()\n",
    "loaded_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20316\\1928918044.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m loaded_model_results = eval_model(model= loaded_model,\n\u001b[0m\u001b[0;32m      4\u001b[0m                                   \u001b[0mdata_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                   \u001b[0mloss_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\Desktop\\AQAUIS\\AQAUIS\\Code\\utils.py\u001b[0m in \u001b[0;36meval_model\u001b[1;34m(model, data_loader, loss_fn, accuracy_fn)\u001b[0m\n\u001b[0;32m     37\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m       \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m       \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "loaded_model.to(device)\n",
    "\n",
    "loaded_model_results = eval_model(model= loaded_model,\n",
    "                                  data_loader = validation_dataloader,\n",
    "                                  loss_fn=loss_fn,\n",
    "                                  accuracy_fn=accuracy_fn)\n",
    "\n",
    "loaded_model_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15b211d7ad94b52292045efb4f8f9084eab8b035832c108b93ce5f33d27f5980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
