{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "from allResNets import *\n",
    "from engine import *\n",
    "from data_transforms import create_transform\n",
    "from dataloaders import *\n",
    "import cv2\n",
    "from data_preparation import *\n",
    "import torch\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes(csv_file: str) -> List[str]:\n",
    "    classes = []\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        labels = []\n",
    "\n",
    "        if(row['Camera Alignment']):\n",
    "            labels.append('Camera Alignment')\n",
    "\n",
    "        if(row['Obstructed Camera']):\n",
    "            labels.append('Obstructed Camera')\n",
    "\n",
    "        if(row['Over lighting']):\n",
    "            labels.append('Over lighting')\n",
    "\n",
    "        if(row['Under lighting']):\n",
    "            labels.append('Under lighting')\n",
    "\n",
    "        if(row['Saturated']):\n",
    "            labels.append('Saturated')\n",
    "\n",
    "        classes.append(labels)\n",
    "    \n",
    "    return classes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageFolderMultiLabel(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, transform = None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.image_paths = \"Quality/dataset/\" + self.data.iloc[:,-1] + \"/\" +  self.data.iloc[:,0] + \".png\"\n",
    "        self.labels = self.data.iloc[:,2:7]\n",
    "        self.classes = find_classes(csv_file)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        classes = self.classes[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label, classes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Quality/all_data_labeled.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15692\\460930067.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdata_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflip_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor_dev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransf_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp_noise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgauss_noise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomImageFolderMultiLabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Quality/all_data_labeled.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15692\\1370162245.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, csv_file, transform)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mCustomImageFolderMultiLabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Quality/dataset/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1442\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1735\u001b[1;33m             self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Quality/all_data_labeled.csv'"
     ]
    }
   ],
   "source": [
    "image_shape = (1080, 1920)\n",
    "resize_factor = 0.3\n",
    "resize = np.multiply(image_shape,resize_factor)\n",
    "resize = [int(resize[0]), int(resize[1])]\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "data_transform = create_transform(resize=resize, rotate=10, flip_h = True, color_dev=True, transf_tensor=True, normalize=True, sp_noise=True, gauss_noise=True)\n",
    "\n",
    "data = CustomImageFolderMultiLabel(csv_file=\"Quality/all_data_labeled.csv\",transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.8510, -0.8510, -0.8431,  ..., -0.8510, -0.8431, -0.8510],\n",
       "          [-0.8510, -0.8431, -0.8431,  ..., -0.8510, -0.8431, -0.8510],\n",
       "          [-0.8510, -0.8510, -0.8510,  ..., -0.8510, -0.8510, -0.8431],\n",
       "          ...,\n",
       "          [-0.8431, -0.8431, -0.8510,  ..., -0.8510, -0.8431, -0.8431],\n",
       "          [-0.8510,  0.9922, -0.8431,  ..., -0.8431, -0.8431, -0.8510],\n",
       "          [-0.8510, -0.8431, -0.8431,  ..., -0.8510, -0.8431, -0.8431]],\n",
       " \n",
       "         [[-0.8510, -0.8431, -0.8431,  ..., -0.8431, -0.8431, -0.8510],\n",
       "          [-0.8510, -0.8510, -0.8510,  ..., -0.8431, -0.8510, -0.8510],\n",
       "          [-0.8431, -0.8510, -0.8510,  ..., -0.8431, -0.8510, -0.8510],\n",
       "          ...,\n",
       "          [-0.8510, -0.8510, -0.8431,  ..., -0.8510, -0.8431, -0.8510],\n",
       "          [-0.8510,  1.0000, -0.8510,  ..., -0.8510, -0.8510, -0.8510],\n",
       "          [-0.8510, -0.8510, -0.8431,  ..., -0.8510, -0.8431, -0.8431]],\n",
       " \n",
       "         [[-0.8431, -0.8431, -0.8431,  ..., -0.8510, -0.8510, -0.8431],\n",
       "          [-0.8431, -0.8510, -0.8431,  ..., -0.8510, -0.8510, -0.8510],\n",
       "          [-0.8510, -0.8431, -0.8510,  ..., -0.8431, -0.8510, -0.8510],\n",
       "          ...,\n",
       "          [-0.8431, -0.8510, -0.8510,  ..., -0.8431, -0.8431, -0.8431],\n",
       "          [-0.8510,  0.9922, -0.8431,  ..., -0.8510, -0.8510, -0.8431],\n",
       "          [-0.8431, -0.8431, -0.8510,  ..., -0.8431, -0.8431, -0.8431]]]),\n",
       " Camera Alignment     1\n",
       " Obstructed Camera    0\n",
       " Over lighting        1\n",
       " Under lighting       0\n",
       " Saturated            0\n",
       " Name: 0, dtype: int64,\n",
       " ['Camera Alignment', 'Over lighting'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label, classes = data.__getitem__(0)\n",
    "image, label, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from utils import *\n",
    "\n",
    "change_to_disk()\n",
    "\n",
    "# Open the input and output files\n",
    "with open('Quality/data/data_labeled_wos.csv', 'r') as input_file, open('Quality/data/data_labeled_wos_joined_double.csv', 'w', newline='') as output_file:\n",
    "    # Create a CSV reader and writer objects\n",
    "    reader = csv.reader(input_file)\n",
    "    writer = csv.writer(output_file)\n",
    "    \n",
    "    # Iterate through the rows in the input file\n",
    "    for row in reader:\n",
    "        # Process the row (e.g., filter out unwanted rows, transform data, etc.)\n",
    "        # In this example, we simply write the row to the output file\n",
    "        #if (row[2] == \"1\") or (row[3] == \"1\") or row[4] == \"1\" or row[5] == \"1\":\n",
    "        if not (row[5] == \"0\" ):\n",
    "            #print(\"hey\")\n",
    "            row[4] = 2    \n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the input and output files\n",
    "with open('Quality/data_labeled.csv', 'r') as input_file, open('Quality/train_data.csv', 'w', newline='') as output_file:\n",
    "    # Create a CSV reader and writer objects\n",
    "    reader = csv.reader(input_file)\n",
    "    writer = csv.writer(output_file)\n",
    "    \n",
    "    # Iterate through the rows in the input file\n",
    "    for row in reader:\n",
    "        # Process the row (e.g., filter out unwanted rows, transform data, etc.)\n",
    "        # In this example, we simply write the row to the output file\n",
    "        if row[0].startswith(\"Qa_align_1_0_\"):\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from utils import *\n",
    "change_to_disk()\n",
    "\n",
    "# Open the input and output files\n",
    "with open('Quality/data/double_data/data_labeled_wos_joined_double.csv', 'r') as input_file, open('Quality/data/placeholder.csv','w', newline='') as placeholder_file:\n",
    "    # Create a CSV reader and writer objects\n",
    "    reader = csv.reader(input_file)\n",
    "    \n",
    "    placeholder_writer = csv.writer(placeholder_file)\n",
    "    counter = 0\n",
    "\n",
    "    \n",
    "    # Iterate through the rows in the input file\n",
    "    for row in reader:\n",
    "        # Process the row (e.g., filter out unwanted rows, transform data, etc.)\n",
    "        # In this example, we simply write the row to the output file\n",
    "        if row[5].startswith(\"4_Under_lighting\") and row[0].startswith(\"Qa_Ulight_5_1\"):\n",
    "            counter = counter+1\n",
    "            placeholder_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/placeholder.csv','r') as placeholder_file, open('Quality/data/double_data/train_data_double.csv', 'a', newline='') as train_file, open('Quality/data/double_data/test_validation_data_double.csv','a',newline='') as test_val_file:\n",
    "    reader = csv.reader(placeholder_file)\n",
    "    train_writer = csv.writer(train_file)\n",
    "    test_val_writer = csv.writer(test_val_file)\n",
    "    split_count = 0\n",
    "\n",
    "    for row in reader:\n",
    "        if 0.7*counter > split_count:\n",
    "            train_writer.writerow(row)\n",
    "        elif 0.8*counter < split_count:\n",
    "            test_val_writer.writerow(row)\n",
    "        \n",
    "        split_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split in classes with 1k per class / whole class\n",
    "\n",
    "classes = [\"1_Camera_alignment\", \"2_Obstructed_Cameras\", \"3_Over_lighting\", \"4_Under_lighting\", \"5_Saturated\"]\n",
    "\n",
    "with open('Quality/data/train_data.csv','r') as train_data_file, open('Quality/data/test_validation_data.csv', 'r') as test_val_data_file, open('Quality/data/split_1k_train_data.csv','w',newline='') as split_1k_train_data_file, open('Quality/data/split_1k_test_data.csv','w',newline='') as split_1k_test_data_file, open('Quality/data/split_1k_validation_data.csv','w',newline='') as split_1k_validation_data_file:\n",
    "    reader_train = csv.reader(train_data_file)\n",
    "    reader_test_validation = csv.reader(test_val_data_file)\n",
    "\n",
    "    row_count_test_val = sum(1 for row in reader_test_validation)\n",
    "    row_count_train = sum(1 for row in reader_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/train_data.csv','r') as train_data_file, open('Quality/data/test_validation_data.csv', 'r') as test_val_data_file, open('Quality/data/split_1k_train_data.csv','w',newline='') as split_1k_train_data_file, open('Quality/data/split_1k_test_data.csv','w',newline='') as split_1k_test_data_file, open('Quality/data/split_1k_validation_data.csv','w',newline='') as split_1k_validation_data_file:\n",
    "    reader_train = csv.reader(train_data_file)\n",
    "    reader_test_validation = csv.reader(test_val_data_file)\n",
    "\n",
    "    split_1k_train_writer = csv.writer(split_1k_train_data_file)\n",
    "    split_1k_validation_writer = csv.writer(split_1k_validation_data_file)\n",
    "    split_1k_test_writer = csv.writer(split_1k_test_data_file)\n",
    "\n",
    "    num_files = 5000\n",
    "    array_range_train = range(0,row_count_train)\n",
    "    array_range_validation = range(0,row_count_test_val)\n",
    "    array_range_test = range(0,row_count_test_val)\n",
    "    \n",
    "    array_train = random.sample(array_range_train, int(num_files*0.8))\n",
    "    array_validation = random.sample(array_range_validation, int(num_files*0.1))\n",
    "    array_test = random.sample(array_range_test,int(num_files*0.1))\n",
    "\n",
    "    for i,row in enumerate(reader_test_validation):\n",
    "        if(i in array_test):\n",
    "            split_1k_test_writer.writerow(row)\n",
    "        elif(i in array_validation):\n",
    "            split_1k_validation_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(reader_train):\n",
    "        if(i in array_train):\n",
    "            split_1k_train_writer.writerow(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação por classes para depois conseguir extrair o numero que é necessário por classe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/double_data/test_validation_data_double.csv','r') as train_data_file, open('Quality/data/test_validation_by_classes/1_Camera_alignment.csv', 'w', newline='') as camera_alignment_file, open('Quality/data/test_validation_by_classes/2_Obstructed_cameras.csv', 'w', newline='') as obstructed_cameras_file, open('Quality/data/test_validation_by_classes/3_Over_lighting.csv', 'w', newline='') as over_lighting_file, open('Quality/data/test_validation_by_classes/4_Under_lighting.csv', 'w', newline='') as under_lighting_file:\n",
    "    reader_train = csv.reader(train_data_file)\n",
    "\n",
    "    writer_camera_alignment = csv.writer(camera_alignment_file)\n",
    "    writer_obstructed_cameras = csv.writer(obstructed_cameras_file)\n",
    "    writer_over_lighting = csv.writer(over_lighting_file)\n",
    "    writer_under_lighting = csv.writer(under_lighting_file)\n",
    "\n",
    "    for row in reader_train:\n",
    "        if row[5].startswith(\"1_Camera_alignment\"):\n",
    "            writer_camera_alignment.writerow(row)\n",
    "        elif row[5].startswith(\"2_Obstructed_cameras\"):\n",
    "            writer_obstructed_cameras.writerow(row)\n",
    "        elif row[5].startswith(\"3_Over_lighting\"):\n",
    "            writer_over_lighting.writerow(row)\n",
    "        elif row[5].startswith(\"4_Under_lighting\"):\n",
    "            writer_under_lighting.writerow(row)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentar agora equilibrar as classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/train_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/train_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/train_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/train_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "\n",
    "    row_count_camera_alignment = sum(1 for row in camera_alignment_reader)\n",
    "    row_count_obstructed_cameras = sum(1 for row in obstructed_cameras_reader)\n",
    "    row_count_over_lighting = sum(1 for row in over_lighting_reader)\n",
    "    row_count_under_lighting = sum(1 for row in under_lighting_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10468\\2439525771.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0marray_camera_alignment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_range_camera_alignment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_per_class_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0marray_obstructed_cameras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_range_obstructed_cameras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_per_class_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0marray_over_lighting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_range_over_lighting\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_per_class_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0marray_under_lighting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_range_under_lighting\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_per_class_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k, counts)\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0mrandbelow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m21\u001b[0m        \u001b[1;31m# size of a small set minus size of an empty list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "with open('Quality/data/split_5k_train_data_single.csv','a', newline='') as train_data_file, open('Quality/data/train_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/train_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/train_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/train_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "    img_per_class_train = 800\n",
    "\n",
    "    train_writer = csv.writer(train_data_file)\n",
    "\n",
    "    array_range_camera_alignment = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting = range(0, row_count_under_lighting)\n",
    "\n",
    "    array_camera_alignment = random.sample(array_range_camera_alignment, img_per_class_train)\n",
    "    array_obstructed_cameras = random.sample(array_range_obstructed_cameras, img_per_class_train)\n",
    "    array_over_lighting = random.sample(array_range_over_lighting, img_per_class_train)\n",
    "    array_under_lighting = random.sample(array_range_under_lighting, img_per_class_train)\n",
    "\n",
    "    for i,row in enumerate(camera_alignment_reader):\n",
    "        if i in array_camera_alignment:\n",
    "            train_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(obstructed_cameras_reader):\n",
    "        if i in array_obstructed_cameras:\n",
    "            train_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(over_lighting_reader):\n",
    "        if i in array_over_lighting:\n",
    "            train_writer.writerow(row)\n",
    "    \n",
    "    for i,row in enumerate(under_lighting_reader):\n",
    "        if i in array_under_lighting:\n",
    "            train_writer.writerow(row)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/test_validation_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/test_validation_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/test_validation_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/test_validation_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "\n",
    "    row_count_camera_alignment = sum(1 for row in camera_alignment_reader)\n",
    "    row_count_obstructed_cameras = sum(1 for row in obstructed_cameras_reader)\n",
    "    row_count_over_lighting = sum(1 for row in over_lighting_reader)\n",
    "    row_count_under_lighting = sum(1 for row in under_lighting_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/split_5k_test_data.csv','a', newline='') as test_data_file, open('Quality/data/split_5k_validation_data.csv','a', newline='') as validation_data_file , open('Quality/data/test_validation_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/test_validation_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/test_validation_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/test_validation_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file :\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "    img_per_class_val_test = 500\n",
    "\n",
    "    test_writer = csv.writer(test_data_file)\n",
    "    validation_writer = csv.writer(validation_data_file)\n",
    "\n",
    "    array_range_camera_alignment_test = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras_test = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting_test = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting_test = range(0, row_count_under_lighting)\n",
    "    \n",
    "    array_camera_alignment_test = random.sample(array_range_camera_alignment_test, img_per_class_val_test)\n",
    "    array_obstructed_cameras_test = random.sample(array_range_obstructed_cameras_test, img_per_class_val_test)\n",
    "    array_over_lighting_test = random.sample(array_range_over_lighting_test, img_per_class_val_test)\n",
    "    array_under_lighting_test = random.sample(array_range_under_lighting_test, img_per_class_val_test)\n",
    "\n",
    "    array_range_camera_alignment_validation = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras_validation = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting_validation = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting_validation = range(0, row_count_under_lighting)\n",
    "    \n",
    "    array_camera_alignment_validation = random.sample(array_range_camera_alignment_validation, img_per_class_val_test)\n",
    "    array_obstructed_cameras_validation = random.sample(array_range_obstructed_cameras_validation, img_per_class_val_test)\n",
    "    array_over_lighting_validation = random.sample(array_range_over_lighting_validation, img_per_class_val_test)\n",
    "    array_under_lighting_validation = random.sample(array_range_under_lighting_validation, img_per_class_val_test)\n",
    "\n",
    "\n",
    "    for i,row in enumerate(camera_alignment_reader):\n",
    "        if i in array_camera_alignment_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_camera_alignment_validation:\n",
    "            validation_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(obstructed_cameras_reader):\n",
    "        if i in array_obstructed_cameras_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_obstructed_cameras_validation:\n",
    "            validation_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(over_lighting_reader):\n",
    "        if i in array_over_lighting_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_over_lighting_validation:\n",
    "            validation_writer.writerow(row)\n",
    "    \n",
    "    for i,row in enumerate(under_lighting_reader):\n",
    "        if i in array_under_lighting_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_under_lighting_validation:\n",
    "            validation_writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificado para 3 classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/train_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/train_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/train_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/train_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "\n",
    "    row_count_camera_alignment = sum(1 for row in camera_alignment_reader)\n",
    "    row_count_obstructed_cameras = sum(1 for row in obstructed_cameras_reader)\n",
    "    row_count_over_lighting = sum(1 for row in over_lighting_reader)\n",
    "    row_count_under_lighting = sum(1 for row in under_lighting_reader)\n",
    "    row_count_lighting_issues = row_count_over_lighting + row_count_under_lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/split_1k_train_data_double.csv','a', newline='') as train_data_file, open('Quality/data/train_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/train_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/train_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/train_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "    img_per_class_train = 800\n",
    "\n",
    "    train_writer = csv.writer(train_data_file)\n",
    "\n",
    "    array_range_camera_alignment = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting = range(0, row_count_under_lighting)\n",
    "\n",
    "    array_camera_alignment = random.sample(array_range_camera_alignment, img_per_class_train)\n",
    "    array_obstructed_cameras = random.sample(array_range_obstructed_cameras, img_per_class_train)\n",
    "    array_over_lighting = random.sample(array_range_over_lighting, int(img_per_class_train/2))\n",
    "    array_under_lighting = random.sample(array_range_under_lighting, int(img_per_class_train/2))\n",
    "\n",
    "    for i,row in enumerate(camera_alignment_reader):\n",
    "        if i in array_camera_alignment:\n",
    "            train_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(obstructed_cameras_reader):\n",
    "        if i in array_obstructed_cameras:\n",
    "            train_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(over_lighting_reader):\n",
    "        if i in array_over_lighting:\n",
    "            train_writer.writerow(row)\n",
    "    \n",
    "    for i,row in enumerate(under_lighting_reader):\n",
    "        if i in array_under_lighting:\n",
    "            train_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/test_validation_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/test_validation_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/test_validation_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/test_validation_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "\n",
    "    row_count_camera_alignment = sum(1 for row in camera_alignment_reader)\n",
    "    row_count_obstructed_cameras = sum(1 for row in obstructed_cameras_reader)\n",
    "    row_count_over_lighting = sum(1 for row in over_lighting_reader)\n",
    "    row_count_under_lighting = sum(1 for row in under_lighting_reader)\n",
    "    row_count_lighting_issues = row_count_over_lighting + row_count_under_lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/split_1k_test_data_double.csv','a', newline='') as test_data_file, open('Quality/data/split_1k_validation_data_double.csv','a', newline='') as validation_data_file , open('Quality/data/test_validation_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/test_validation_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/test_validation_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/test_validation_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file :\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "    img_per_class_val_test = 120\n",
    "\n",
    "    test_writer = csv.writer(test_data_file)\n",
    "    validation_writer = csv.writer(validation_data_file)\n",
    "\n",
    "    array_range_camera_alignment_test = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras_test = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting_test = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting_test = range(0, row_count_under_lighting)\n",
    "    \n",
    "    array_camera_alignment_test = random.sample(array_range_camera_alignment_test, img_per_class_val_test)\n",
    "    array_obstructed_cameras_test = random.sample(array_range_obstructed_cameras_test, img_per_class_val_test)\n",
    "    array_over_lighting_test = random.sample(array_range_over_lighting_test, int(img_per_class_val_test/2))\n",
    "    array_under_lighting_test = random.sample(array_range_under_lighting_test, int(img_per_class_val_test/2))\n",
    "\n",
    "    array_range_camera_alignment_validation = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras_validation = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting_validation = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting_validation = range(0, row_count_under_lighting)\n",
    "    \n",
    "    array_camera_alignment_validation = random.sample(array_range_camera_alignment_validation, img_per_class_val_test)\n",
    "    array_obstructed_cameras_validation = random.sample(array_range_obstructed_cameras_validation, img_per_class_val_test)\n",
    "    array_over_lighting_validation = random.sample(array_range_over_lighting_validation, int(img_per_class_val_test/2))\n",
    "    array_under_lighting_validation = random.sample(array_range_under_lighting_validation, int(img_per_class_val_test/2))\n",
    "\n",
    "\n",
    "    for i,row in enumerate(camera_alignment_reader):\n",
    "        if i in array_camera_alignment_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_camera_alignment_validation:\n",
    "            validation_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(obstructed_cameras_reader):\n",
    "        if i in array_obstructed_cameras_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_obstructed_cameras_validation:\n",
    "            validation_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(over_lighting_reader):\n",
    "        if i in array_over_lighting_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_over_lighting_validation:\n",
    "            validation_writer.writerow(row)\n",
    "    \n",
    "    for i,row in enumerate(under_lighting_reader):\n",
    "        if i in array_under_lighting_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_under_lighting_validation:\n",
    "            validation_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visibility_frames\\Video_10_Poor does not exist, creating one...\n",
      "['Visibility\\\\Video_10_Poor\\\\20210329114717566@Block209F_HD1_PORT.mp4', 'Visibility\\\\Video_10_Poor\\\\20210329114717590@Block209F_HD2_CENTRE.mp4', 'Visibility\\\\Video_10_Poor\\\\20210329114717609@Block209F_HD3_STBD.mp4']\n",
      "Frame:0 | Success:True\n",
      "Frame:500 | Success:True\n",
      "Frame:1000 | Success:True\n",
      "Frame:1500 | Success:True\n",
      "Frame:2000 | Success:True\n",
      "Frame:2500 | Success:True\n",
      "Frame:3000 | Success:True\n",
      "Frame:3500 | Success:True\n",
      "Frame:4000 | Success:True\n",
      "Frame:4500 | Success:True\n",
      "Frame:5000 | Success:True\n",
      "Frame:5500 | Success:True\n",
      "Frame:6000 | Success:True\n",
      "Frame:6500 | Success:True\n",
      "Frame:7000 | Success:True\n",
      "Frame:7500 | Success:True\n",
      "Frame:8000 | Success:True\n",
      "Frame:8500 | Success:True\n",
      "Frame:9000 | Success:True\n",
      "Frame:9500 | Success:True\n",
      "Frame:10000 | Success:True\n",
      "Frame:10500 | Success:True\n",
      "Frame:11000 | Success:True\n",
      "Frame:11500 | Success:True\n",
      "Frame:12000 | Success:True\n",
      "Frame:12500 | Success:True\n",
      "Frame:13000 | Success:True\n",
      "Frame:13500 | Success:True\n",
      "Frame:14000 | Success:True\n",
      "Frame:14500 | Success:True\n",
      "Frame:15000 | Success:True\n",
      "Frame:15500 | Success:True\n",
      "Frame:16000 | Success:True\n",
      "Frame:16500 | Success:True\n",
      "Frame:17000 | Success:True\n",
      "Frame:17500 | Success:True\n",
      "Frame:18000 | Success:True\n",
      "Frame:18500 | Success:True\n",
      "Frame:19000 | Success:True\n",
      "Frame:19500 | Success:True\n",
      "Frame:20000 | Success:True\n",
      "Frame:20500 | Success:True\n",
      "Frame:21000 | Success:True\n",
      "Frame:21500 | Success:True\n",
      "Frame:22000 | Success:True\n",
      "Frame:22500 | Success:True\n",
      "Frame:23000 | Success:True\n",
      "Frame:23500 | Success:True\n",
      "Frame:24000 | Success:True\n",
      "Frame:24500 | Success:True\n",
      "Frame:25000 | Success:True\n",
      "Frame:25500 | Success:True\n",
      "Frame:26000 | Success:True\n",
      "Frame:26500 | Success:True\n",
      "Frame:27000 | Success:True\n",
      "Frame:27500 | Success:True\n",
      "Frame:28000 | Success:True\n",
      "Frame:28500 | Success:True\n",
      "Frame:29000 | Success:True\n",
      "Frame:29500 | Success:True\n",
      "Frame:30000 | Success:True\n",
      "Frame:30500 | Success:True\n",
      "Frame:31000 | Success:True\n",
      "Frame:31500 | Success:True\n",
      "Frame:32000 | Success:True\n",
      "Frame:32500 | Success:True\n",
      "Frame:33000 | Success:True\n",
      "Frame:0 | Success:True\n",
      "Frame:500 | Success:True\n",
      "Frame:1000 | Success:True\n",
      "Frame:1500 | Success:True\n",
      "Frame:2000 | Success:True\n",
      "Frame:2500 | Success:True\n",
      "Frame:3000 | Success:True\n",
      "Frame:3500 | Success:True\n",
      "Frame:4000 | Success:True\n",
      "Frame:4500 | Success:True\n",
      "Frame:5000 | Success:True\n",
      "Frame:5500 | Success:True\n",
      "Frame:6000 | Success:True\n",
      "Frame:6500 | Success:True\n",
      "Frame:7000 | Success:True\n",
      "Frame:7500 | Success:True\n",
      "Frame:8000 | Success:True\n",
      "Frame:8500 | Success:True\n",
      "Frame:9000 | Success:True\n",
      "Frame:9500 | Success:True\n",
      "Frame:10000 | Success:True\n",
      "Frame:10500 | Success:True\n",
      "Frame:11000 | Success:True\n",
      "Frame:11500 | Success:True\n",
      "Frame:12000 | Success:True\n",
      "Frame:12500 | Success:True\n",
      "Frame:13000 | Success:True\n",
      "Frame:13500 | Success:True\n",
      "Frame:14000 | Success:True\n",
      "Frame:14500 | Success:True\n",
      "Frame:15000 | Success:True\n",
      "Frame:15500 | Success:True\n",
      "Frame:16000 | Success:True\n",
      "Frame:16500 | Success:True\n",
      "Frame:17000 | Success:True\n",
      "Frame:17500 | Success:True\n",
      "Frame:18000 | Success:True\n",
      "Frame:18500 | Success:True\n",
      "Frame:19000 | Success:True\n",
      "Frame:19500 | Success:True\n",
      "Frame:20000 | Success:True\n",
      "Frame:20500 | Success:True\n",
      "Frame:21000 | Success:True\n",
      "Frame:21500 | Success:True\n",
      "Frame:22000 | Success:True\n",
      "Frame:22500 | Success:True\n",
      "Frame:23000 | Success:True\n",
      "Frame:23500 | Success:True\n",
      "Frame:24000 | Success:True\n",
      "Frame:24500 | Success:True\n",
      "Frame:25000 | Success:True\n",
      "Frame:25500 | Success:True\n",
      "Frame:26000 | Success:True\n",
      "Frame:26500 | Success:True\n",
      "Frame:27000 | Success:True\n",
      "Frame:27500 | Success:True\n",
      "Frame:28000 | Success:True\n",
      "Frame:28500 | Success:True\n"
     ]
    }
   ],
   "source": [
    "#Change disk directory\n",
    "base_path = Path(\"E:/Users/joaor/NSP/2021\")\n",
    "if(Path().cwd() != Path(r\"E:\\Users\\joaor\\NSP\\2021\")):\n",
    "    os.chdir(base_path)\n",
    "\n",
    "video_name = \"Video_10_Poor\"\n",
    "\n",
    "videos_folder = Path(\"Visibility/\" + video_name)\n",
    "videos = glob.glob(str(videos_folder) + \"/*.mp4\")\n",
    "\n",
    "save_folder = Path(\"Visibility_frames/\"+video_name)\n",
    "check_dir(save_folder)\n",
    "save_folder = str(save_folder / video_name)\n",
    "\n",
    "print(videos)\n",
    "\n",
    "for i,video in enumerate(videos):\n",
    "    convert_mp4_to_png(video  ,save_folder+\"_\"+str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15b211d7ad94b52292045efb4f8f9084eab8b035832c108b93ce5f33d27f5980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
