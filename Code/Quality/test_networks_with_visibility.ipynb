{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "from allResNets import *\n",
    "from engine import *\n",
    "from data_transforms import create_transform\n",
    "from dataloaders import *\n",
    "\n",
    "change_to_disk()\n",
    "data_dir = Path(\"clean_split_1k/\")\n",
    "models_path = Path('Quality/Models_test/')\n",
    "check_dir(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"Finds the class folder names in a target directory.\"\"\"\n",
    "\n",
    "    # 1. Get the class names by scanning the target directory\n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "\n",
    "    # 2. Raise an error if class names could not be found\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}... please check file structure.\")\n",
    "\n",
    "    # 3. Create a dictionary of index labels (computers prefer numbers rather than strings as labels)\n",
    "\n",
    "    class_to_idx = {}\n",
    "    for i, class_name in enumerate(classes):\n",
    "        id = np.zeros(len(classes))\n",
    "        id[i] = 1\n",
    "        class_to_idx[class_name] = id\n",
    "        \n",
    "    return classes, class_to_idx\n",
    "\n",
    "class CustomImageFolderMultiLabel(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transform = None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes, self.class_to_idx = find_classes(root)\n",
    "        for i, class_name in enumerate(self.classes):\n",
    "            class_path = os.path.join(root, class_name)\n",
    "            for image_path in os.listdir(class_path):\n",
    "                self.image_paths.append(os.path.join(class_path, image_path))\n",
    "                label = [0]*len(self.classes)\n",
    "                label[i] = 1\n",
    "                self.labels.append(torch.tensor(label))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "def create_dataloaders_multilabel(\n",
    "    data_dir: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int,\n",
    "    num_workers:int = NUM_WORKERS):\n",
    "\n",
    "    \"\"\"\n",
    "    Create dataloaders for the data split into train/validation/test\n",
    "\n",
    "    Args:\n",
    "    data_dir : Path to data directory with (train/validation/test split).\n",
    "    transform : torchvision transforms to perform on training, validation and testing data.\n",
    "    batch_size : Number of samples per batch in each of the DataLoaders.\n",
    "    num_workers : An integer for number of workers per DataLoader.\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "    train dataloader, validation_dataloader, test_dataloader, train_data, validation_data, test_data, class_names\n",
    "    \"\"\"\n",
    "\n",
    "    train_dir = data_dir / \"train/\"\n",
    "    validation_dir = data_dir / \"validation/\"\n",
    "    test_dir = data_dir / \"test/\"\n",
    "\n",
    "\n",
    "    # Use ImageFolder to create dataset(s)\n",
    "    train_data = CustomImageFolderMultiLabel(root=train_dir,\n",
    "                                    transform=transform) # a transform for the data\n",
    "    \n",
    "    validation_data = CustomImageFolderMultiLabel(root=validation_dir,\n",
    "                                    transform=transform)\n",
    "\n",
    "    test_data = CustomImageFolderMultiLabel(root=test_dir,\n",
    "                                    transform=transform)\n",
    "\n",
    "\n",
    "    #Get classes\n",
    "    class_names = train_data.class_to_idx\n",
    "\n",
    "    # Turn images into data loaders\n",
    "    train_dataloader = DataLoader(dataset=train_data,\n",
    "                                batch_size=batch_size,\n",
    "                                num_workers=num_workers,\n",
    "                                shuffle=True)\n",
    "\n",
    "    test_dataloader = DataLoader(dataset=test_data,\n",
    "                                batch_size=batch_size,\n",
    "                                num_workers=num_workers,\n",
    "                                shuffle=False)\n",
    "\n",
    "    validation_dataloader = DataLoader(dataset=validation_data,\n",
    "                                        batch_size=batch_size,\n",
    "                                        num_workers=num_workers,\n",
    "                                        shuffle=False)\n",
    "\n",
    "    return train_dataloader, validation_dataloader, test_dataloader, train_data, validation_data, test_data, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (1080, 1920)\n",
    "resize_factor = 0.1\n",
    "resize = np.multiply(image_shape,resize_factor)\n",
    "resize = [int(resize[0]), int(resize[1])]\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "data_transform = create_transform(resize=resize, rotate=10, flip_h = True, color_dev=True, transf_tensor=True, normalize=True, sp_noise=True, gauss_noise=True)\n",
    "\n",
    "train_dl, validation_dl, test_dl, train_data, validation_data, test_data, class_names = create_dataloaders_multilabel(data_dir, transform = data_transform, batch_size=BATCH_SIZE, num_workers= NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2\n",
    "lr = 0.001\n",
    "device = get_device()\n",
    "\n",
    "resnet18 = ResNet18()\n",
    "\n",
    "#Changed in order to fit the multilabel problem\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality\\Models_test\\ResNet18 does not exist, creating one...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d0ed07b2924947bdc22a01048b3bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"ResNet18\"\n",
    "model_folder_path = models_path / model_name\n",
    "check_dir(model_folder_path)\n",
    "model_name_folder_path = model_folder_path / model_name\n",
    "\n",
    "#Train ResNet18\n",
    "resnet18.to(device)\n",
    "nadam_optim = torch.optim.NAdam(params=resnet18.parameters(), lr=lr)\n",
    "train_resnet18_results, train_time_resnet18 = train(resnet18, train_dl, validation_dl, optimizer=nadam_optim, loss_fn=loss_fn, epochs=NUM_EPOCHS, name_save=model_name_folder_path, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
