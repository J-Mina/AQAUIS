{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "from allResNets import *\n",
    "from engine import *\n",
    "from data_transforms import create_transform\n",
    "from dataloaders import *\n",
    "\n",
    "change_to_disk()\n",
    "data_dir = Path(\"clean_split_1k/\")\n",
    "models_path = Path('Quality/Models_test/')\n",
    "check_dir(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (1080, 1920)\n",
    "resize_factor = 0.3\n",
    "resize = np.multiply(image_shape,resize_factor)\n",
    "resize = [int(resize[0]), int(resize[1])]\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "data_transform = create_transform(resize=resize, rotate=10, flip_h = True, color_dev=True, transf_tensor=True, normalize=True, sp_noise=True, gauss_noise=True)\n",
    "\n",
    "train_dl, validation_dl, test_dl, train_data, validation_data, test_data, class_names = create_dataloaders_multilabel(data_dir, transform = data_transform, batch_size=BATCH_SIZE, num_workers= NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "lr = 0.001\n",
    "device = get_device()\n",
    "\n",
    "resnet18 = ResNet18()\n",
    "\n",
    "#Combines the sigmoid with the BinaryCrossEntropy\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4858aa3261a41dcb89471e854cf8c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.3796 | train_acc: 0.2655 | validation_loss: 0.6396 | validation_acc: 0.3105\n",
      "Epoch: 2 | train_loss: 0.3080 | train_acc: 0.3917 | validation_loss: 1.7826 | validation_acc: 0.1992\n",
      "Epoch: 3 | train_loss: 0.2798 | train_acc: 0.4640 | validation_loss: 0.2736 | validation_acc: 0.4492\n",
      "Epoch: 4 | train_loss: 0.2615 | train_acc: 0.5110 | validation_loss: 1.0050 | validation_acc: 0.2969\n",
      "Epoch: 5 | train_loss: 0.2392 | train_acc: 0.5670 | validation_loss: 0.8186 | validation_acc: 0.2812\n",
      "Epoch: 6 | train_loss: 0.2146 | train_acc: 0.6232 | validation_loss: 1.0033 | validation_acc: 0.4141\n",
      "Epoch: 7 | train_loss: 0.1873 | train_acc: 0.6860 | validation_loss: 1.0143 | validation_acc: 0.3008\n",
      "Epoch: 8 | train_loss: 0.1896 | train_acc: 0.6833 | validation_loss: 2.8340 | validation_acc: 0.2539\n",
      "Epoch: 9 | train_loss: 0.1696 | train_acc: 0.7210 | validation_loss: 0.7490 | validation_acc: 0.4844\n",
      "Epoch: 10 | train_loss: 0.1614 | train_acc: 0.7352 | validation_loss: 0.3747 | validation_acc: 0.5977\n",
      "Epoch: 11 | train_loss: 0.1516 | train_acc: 0.7650 | validation_loss: 0.6761 | validation_acc: 0.4727\n",
      "Epoch: 12 | train_loss: 0.1445 | train_acc: 0.7685 | validation_loss: 2.4474 | validation_acc: 0.3184\n",
      "Epoch: 13 | train_loss: 0.1353 | train_acc: 0.7833 | validation_loss: 0.6632 | validation_acc: 0.4062\n",
      "Epoch: 14 | train_loss: 0.1297 | train_acc: 0.7913 | validation_loss: 1.2360 | validation_acc: 0.4355\n",
      "Epoch: 15 | train_loss: 0.1285 | train_acc: 0.7993 | validation_loss: 0.3153 | validation_acc: 0.6191\n",
      "Epoch: 16 | train_loss: 0.1210 | train_acc: 0.8080 | validation_loss: 0.6696 | validation_acc: 0.5078\n",
      "Epoch: 17 | train_loss: 0.1133 | train_acc: 0.8230 | validation_loss: 0.7089 | validation_acc: 0.5117\n",
      "Epoch: 18 | train_loss: 0.1149 | train_acc: 0.8227 | validation_loss: 0.4379 | validation_acc: 0.5156\n",
      "Epoch: 19 | train_loss: 0.1069 | train_acc: 0.8375 | validation_loss: 0.5294 | validation_acc: 0.5410\n",
      "Epoch: 20 | train_loss: 0.1081 | train_acc: 0.8305 | validation_loss: 2.4717 | validation_acc: 0.3887\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ResNet18\"\n",
    "model_folder_path = models_path / model_name\n",
    "check_dir(model_folder_path)\n",
    "model_name_folder_path = model_folder_path / model_name\n",
    "\n",
    "#Train ResNet18\n",
    "resnet18.to(device)\n",
    "nadam_optim = torch.optim.NAdam(params=resnet18.parameters(), lr=lr)\n",
    "train_resnet18_results, train_time_resnet18 = train(resnet18, train_dl, validation_dl, optimizer=nadam_optim, loss_fn=loss_fn, epochs=NUM_EPOCHS, name_save=model_name_folder_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(ResNet18, Path(\"Quality/Models_test/ResNet18/ResNet18_2_2_epcs.pth\"),device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = create_transform(resize=resize, rotate=10, flip_h = True, color_dev=True, transf_tensor=True, normalize=True, sp_noise=True, gauss_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"clean_split_1k/test/2_Good/Vis_good_1_0_frame300.png\")\n",
    "img = transforms(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0.]], grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = loaded_model(img.unsqueeze(0))\n",
    "y = torch.sigmoid(y)\n",
    "y = torch.round(y)\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
