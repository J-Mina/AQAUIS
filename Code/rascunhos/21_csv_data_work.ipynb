{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "from allResNets import *\n",
    "from engine import *\n",
    "from data_transforms import create_transform\n",
    "from dataloaders import *\n",
    "import cv2\n",
    "from data_preparation import *\n",
    "import torch\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes(csv_file: str) -> List[str]:\n",
    "    classes = []\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        labels = []\n",
    "\n",
    "        if(row['Camera Alignment']):\n",
    "            labels.append('Camera Alignment')\n",
    "\n",
    "        if(row['Obstructed Camera']):\n",
    "            labels.append('Obstructed Camera')\n",
    "\n",
    "        if(row['Over lighting']):\n",
    "            labels.append('Over lighting')\n",
    "\n",
    "        if(row['Under lighting']):\n",
    "            labels.append('Under lighting')\n",
    "\n",
    "        if(row['Saturated']):\n",
    "            labels.append('Saturated')\n",
    "\n",
    "        classes.append(labels)\n",
    "    \n",
    "    return classes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageFolderMultiLabel(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, transform = None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.image_paths = \"Quality/dataset/\" + self.data.iloc[:,-1] + \"/\" +  self.data.iloc[:,0] + \".png\"\n",
    "        self.labels = self.data.iloc[:,2:7]\n",
    "        self.classes = find_classes(csv_file)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        classes = self.classes[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label, classes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from utils import *\n",
    "\n",
    "change_to_disk()\n",
    "\n",
    "# Open the input and output files\n",
    "with open('Quality/data/new_data/all_data_wos_double.csv', 'r') as input_file, open('Quality/data/new_data/all_data_wos_double_wcls.csv', 'w', newline='') as output_file:\n",
    "    # Create a CSV reader and writer objects\n",
    "    reader = csv.reader(input_file)\n",
    "    writer = csv.writer(output_file)\n",
    "    \n",
    "    # Iterate through the rows in the input file\n",
    "    for row in reader:\n",
    "        buff = []\n",
    "        # Process the row (e.g., filter out unwanted rows, transform data, etc.)\n",
    "        # In this example, we simply write the row to the output file\n",
    "        #if (row[2] == \"1\") or (row[3] == \"1\") or row[4] == \"1\" or row[5] == \"1\":\n",
    "        if (row[2] == \"1\"):\n",
    "            buff.append('Bad Camera Alignment')\n",
    "        if(row[3] == \"1\"):\n",
    "            buff.append('Obstructed Camera')\n",
    "        if(row[4] == \"1\"):\n",
    "            buff.append('Overlighting')\n",
    "        if(row[4] == \"2\"):\n",
    "            buff.append('Underlighting')\n",
    "        \n",
    "        row[1] = buff\n",
    "\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from utils import *\n",
    "\n",
    "change_to_disk()\n",
    "\n",
    "# Open the input and output files\n",
    "with open('Quality/data/new_data/all_data_wos_double_wcls.csv', 'r') as input_file, open('Quality/data/new_data/all_data_wos_double_wcls_labeled.csv', 'w', newline='') as output_file:\n",
    "    # Create a CSV reader and writer objects\n",
    "    reader = csv.reader(input_file)\n",
    "    writer = csv.writer(output_file)\n",
    "    \n",
    "    # Iterate through the rows in the input file\n",
    "    for row in reader:\n",
    "        # Process the row (e.g., filter out unwanted rows, transform data, etc.)\n",
    "        # In this example, we simply write the row to the output file\n",
    "        if (row[2] == \"1\") or (row[3] == \"1\") or row[4] == \"1\" or row[4] == \"2\":\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the input and output files\n",
    "with open('Quality/data/all_data_labeled_wos.csv', 'r') as input_file, open('Quality/data/double_data/all_data_wos.csv', 'w', newline='') as output_file:\n",
    "    # Create a CSV reader and writer objects\n",
    "    reader = csv.reader(input_file)\n",
    "    writer = csv.writer(output_file)\n",
    "    \n",
    "    # Iterate through the rows in the input file\n",
    "    for row in reader:\n",
    "        # Process the row (e.g., filter out unwanted rows, transform data, etc.)\n",
    "        # In this example, we simply write the row to the output file\n",
    "        if row[0].startswith(\"Qa_align_1_0_\"):\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from utils import *\n",
    "change_to_disk()\n",
    "\n",
    "#list = {\n",
    "# Qa_align_1_0\n",
    "# Qa_align_1_2\n",
    "# Qa_align_2_0\n",
    "# Qa_align_2_2\n",
    "# Qa_align_4_0\n",
    "# Qa_align_4_2\n",
    "# Qa_Obs_1_0\n",
    "# Qa_Obs_1_1\n",
    "# Qa_Obs_2_0\n",
    "# Qa_Obs_2_1\n",
    "# Qa_Obs_2_2\n",
    "# Qa_Obs_4_0\n",
    "# Qa_Obs_4_1\n",
    "# Qa_Obs_4_2\n",
    "# Qa_Obs_5_0\n",
    "# Qa_Obs_5_2\n",
    "# Qa_Obs_6_0\n",
    "# Qa_Obs_6_2\n",
    "# Qa_Obs_7_0\n",
    "# Qa_Obs_7_1\n",
    "# Qa_Obs_7_2\n",
    "# Qa_Obs_9_0\n",
    "# Qa_Obs_9_2\n",
    "# Qa_OL_1_2\n",
    "# Qa_OL_2_2\n",
    "# Qa_OL_3_0\n",
    "# Qa_OL_4_0\n",
    "# Qa_OL_4_2\n",
    "# Qa_OL_5_2\n",
    "# Qa_Ulight_2_0\n",
    "# Qa_Ulight_3_0\n",
    "# Qa_Ulight_4_0\n",
    "# Qa_Ulight_5_0\n",
    "# }\n",
    "\n",
    "# Open the input and output files\n",
    "with open('Quality/data/new_data/all_data_wos_double_wcls_labeled.csv', 'r') as input_file, open('Quality/data/new_data/placeholder.csv','w', newline='') as placeholder_file:\n",
    "    # Create a CSV reader and writer objects\n",
    "    reader = csv.reader(input_file)\n",
    "    \n",
    "    placeholder_writer = csv.writer(placeholder_file)\n",
    "    counter = 0\n",
    "\n",
    "    \n",
    "    # Iterate through the rows in the input file\n",
    "    for row in reader:\n",
    "        # Process the row (e.g., filter out unwanted rows, transform data, etc.)\n",
    "        # In this example, we simply write the row to the output file\n",
    "        if row[0].startswith(\"Qa_Ulight_5_0\"):\n",
    "            counter = counter+1\n",
    "            placeholder_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/new_data/placeholder.csv','r') as placeholder_file, open('Quality/data/new_data/train_data_double.csv', 'a', newline='') as train_file, open('Quality/data/new_data/test_validation_data_double.csv','a',newline='') as test_val_file:\n",
    "    reader = csv.reader(placeholder_file)\n",
    "    train_writer = csv.writer(train_file)\n",
    "    test_val_writer = csv.writer(test_val_file)\n",
    "    split_count = 0\n",
    "\n",
    "    for row in reader:\n",
    "        if 0.7*counter > split_count:\n",
    "            train_writer.writerow(row)\n",
    "        elif 0.8*counter < split_count:\n",
    "            test_val_writer.writerow(row)\n",
    "        \n",
    "        split_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split in classes with 1k per class / whole class\n",
    "\n",
    "classes = [\"1_Camera_alignment\", \"2_Obstructed_Cameras\", \"3_Over_lighting\", \"4_Under_lighting\", \"5_Saturated\"]\n",
    "\n",
    "with open('Quality/data/train_data.csv','r') as train_data_file, open('Quality/data/test_validation_data.csv', 'r') as test_val_data_file, open('Quality/data/split_1k_train_data.csv','w',newline='') as split_1k_train_data_file, open('Quality/data/split_1k_test_data.csv','w',newline='') as split_1k_test_data_file, open('Quality/data/split_1k_validation_data.csv','w',newline='') as split_1k_validation_data_file:\n",
    "    reader_train = csv.reader(train_data_file)\n",
    "    reader_test_validation = csv.reader(test_val_data_file)\n",
    "\n",
    "    row_count_test_val = sum(1 for row in reader_test_validation)\n",
    "    row_count_train = sum(1 for row in reader_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/train_data.csv','r') as train_data_file, open('Quality/data/test_validation_data.csv', 'r') as test_val_data_file, open('Quality/data/split_1k_train_data.csv','w',newline='') as split_1k_train_data_file, open('Quality/data/split_1k_test_data.csv','w',newline='') as split_1k_test_data_file, open('Quality/data/split_1k_validation_data.csv','w',newline='') as split_1k_validation_data_file:\n",
    "    reader_train = csv.reader(train_data_file)\n",
    "    reader_test_validation = csv.reader(test_val_data_file)\n",
    "\n",
    "    split_1k_train_writer = csv.writer(split_1k_train_data_file)\n",
    "    split_1k_validation_writer = csv.writer(split_1k_validation_data_file)\n",
    "    split_1k_test_writer = csv.writer(split_1k_test_data_file)\n",
    "\n",
    "    num_files = 5000\n",
    "    array_range_train = range(0,row_count_train)\n",
    "    array_range_validation = range(0,row_count_test_val)\n",
    "    array_range_test = range(0,row_count_test_val)\n",
    "    \n",
    "    array_train = random.sample(array_range_train, int(num_files*0.8))\n",
    "    array_validation = random.sample(array_range_validation, int(num_files*0.1))\n",
    "    array_test = random.sample(array_range_test,int(num_files*0.1))\n",
    "\n",
    "    for i,row in enumerate(reader_test_validation):\n",
    "        if(i in array_test):\n",
    "            split_1k_test_writer.writerow(row)\n",
    "        elif(i in array_validation):\n",
    "            split_1k_validation_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(reader_train):\n",
    "        if(i in array_train):\n",
    "            split_1k_train_writer.writerow(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação por classes para depois conseguir extrair o numero que é necessário por classe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import csv\n",
    "change_to_disk()\n",
    "\n",
    "with open('Quality/data/new_data/train_data_double.csv','r') as train_data_file, open('Quality/data/new_data/train_by_classes/1_Camera_alignment.csv', 'w', newline='') as camera_alignment_file, open('Quality/data/new_data/train_by_classes/2_Obstructed_cameras.csv', 'w', newline='') as obstructed_cameras_file, open('Quality/data/new_data/train_by_classes/3_Over_lighting.csv', 'w', newline='') as over_lighting_file, open('Quality/data/new_data/train_by_classes/4_Under_lighting.csv', 'w', newline='') as under_lighting_file:\n",
    "    reader_train = csv.reader(train_data_file)\n",
    "\n",
    "    writer_camera_alignment = csv.writer(camera_alignment_file)\n",
    "    writer_obstructed_cameras = csv.writer(obstructed_cameras_file)\n",
    "    writer_over_lighting = csv.writer(over_lighting_file)\n",
    "    writer_under_lighting = csv.writer(under_lighting_file)\n",
    "\n",
    "    for row in reader_train:\n",
    "        if row[5].startswith(\"1_Camera_alignment\"):\n",
    "            writer_camera_alignment.writerow(row)\n",
    "        elif row[5].startswith(\"2_Obstructed_cameras\"):\n",
    "            writer_obstructed_cameras.writerow(row)\n",
    "        elif row[5].startswith(\"3_Over_lighting\"):\n",
    "            writer_over_lighting.writerow(row)\n",
    "        elif row[5].startswith(\"4_Under_lighting\"):\n",
    "            writer_under_lighting.writerow(row)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentar agora equilibrar as classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import csv\n",
    "change_to_disk()\n",
    "\n",
    "with open('Quality/data/new_data/train_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/new_data/train_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/new_data/train_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/new_data/train_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file, open('Quality/data/new_data/train_by_classes/5_Good_Alignment.csv', 'r') as good_alignment_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "    good_alignment_reader = csv.reader(good_alignment_file)\n",
    "\n",
    "\n",
    "    row_count_camera_alignment = sum(1 for row in camera_alignment_reader)\n",
    "    row_count_obstructed_cameras = sum(1 for row in obstructed_cameras_reader)\n",
    "    row_count_over_lighting = sum(1 for row in over_lighting_reader)\n",
    "    row_count_under_lighting = sum(1 for row in under_lighting_reader)\n",
    "    row_count_good_alignment = sum(1 for row in good_alignment_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/new_data/split_1k_train_data_single.csv','a', newline='') as train_data_file, open('Quality/data/new_data/train_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/new_data/train_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/new_data/train_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/new_data/train_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file, open('Quality/data/new_data/train_by_classes/5_Good_Alignment.csv', 'r') as good_alignment_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "    good_alignment_reader = csv.reader(good_alignment_file)\n",
    "\n",
    "    img_per_class_train = 800\n",
    "\n",
    "    train_writer = csv.writer(train_data_file)\n",
    "\n",
    "    array_range_camera_alignment = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting = range(0, row_count_under_lighting)\n",
    "    array_range_good_alignment = range(0, row_count_good_alignment)\n",
    "\n",
    "    array_camera_alignment = random.sample(array_range_camera_alignment, img_per_class_train)\n",
    "    array_obstructed_cameras = random.sample(array_range_obstructed_cameras, img_per_class_train)\n",
    "    array_over_lighting = random.sample(array_range_over_lighting, img_per_class_train)\n",
    "    array_under_lighting = random.sample(array_range_under_lighting, img_per_class_train)\n",
    "    array_good_alignment = random.sample(array_range_good_alignment, img_per_class_train)\n",
    "\n",
    "    for i,row in enumerate(camera_alignment_reader):\n",
    "        if i in array_camera_alignment:\n",
    "            train_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(obstructed_cameras_reader):\n",
    "        if i in array_obstructed_cameras:\n",
    "            train_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(over_lighting_reader):\n",
    "        if i in array_over_lighting:\n",
    "            train_writer.writerow(row)\n",
    "    \n",
    "    for i,row in enumerate(under_lighting_reader):\n",
    "        if i in array_under_lighting:\n",
    "            train_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(good_alignment_reader):\n",
    "        if i in array_good_alignment:\n",
    "            train_writer.writerow(row)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/new_data/test_validation_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/new_data/test_validation_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/new_data/test_validation_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/new_data/test_validation_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file, open('Quality/data/new_data/test_validation_by_classes/5_Good_Alignment.csv', 'r') as good_alignment_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "    good_alignment_reader = csv.reader(good_alignment_file)\n",
    "\n",
    "\n",
    "\n",
    "    row_count_camera_alignment = sum(1 for row in camera_alignment_reader)\n",
    "    row_count_obstructed_cameras = sum(1 for row in obstructed_cameras_reader)\n",
    "    row_count_over_lighting = sum(1 for row in over_lighting_reader)\n",
    "    row_count_under_lighting = sum(1 for row in under_lighting_reader)\n",
    "    row_count_good_alignment = sum(1 for row in good_alignment_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/new_data/split_1k_test_data.csv','a', newline='') as test_data_file, open('Quality/data/new_data/split_1k_validation_data.csv','a', newline='') as validation_data_file , open('Quality/data/new_data/test_validation_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/new_data/test_validation_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/new_data/test_validation_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/new_data/test_validation_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file, open('Quality/data/new_data/test_validation_by_classes/5_Good_Alignment.csv', 'r') as good_alignment_file :\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "    good_alignment_reader = csv.reader(good_alignment_file)\n",
    "\n",
    "    img_per_class_val_test = 100\n",
    "\n",
    "    test_writer = csv.writer(test_data_file)\n",
    "    validation_writer = csv.writer(validation_data_file)\n",
    "\n",
    "    array_range_camera_alignment_test = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras_test = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting_test = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting_test = range(0, row_count_under_lighting)\n",
    "    array_range_good_alignment_test = range(0, row_count_good_alignment)\n",
    "    \n",
    "    array_camera_alignment_test = random.sample(array_range_camera_alignment_test, img_per_class_val_test)\n",
    "    array_obstructed_cameras_test = random.sample(array_range_obstructed_cameras_test, img_per_class_val_test)\n",
    "    array_over_lighting_test = random.sample(array_range_over_lighting_test, img_per_class_val_test)\n",
    "    array_under_lighting_test = random.sample(array_range_under_lighting_test, img_per_class_val_test)\n",
    "    array_good_alignment_test = random.sample(array_range_good_alignment_test, img_per_class_val_test)\n",
    "\n",
    "    array_range_camera_alignment_validation = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras_validation = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting_validation = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting_validation = range(0, row_count_under_lighting)\n",
    "    array_range_good_alignment_validation = range(0, row_count_good_alignment)\n",
    "    \n",
    "    array_camera_alignment_validation = random.sample(array_range_camera_alignment_validation, img_per_class_val_test)\n",
    "    array_obstructed_cameras_validation = random.sample(array_range_obstructed_cameras_validation, img_per_class_val_test)\n",
    "    array_over_lighting_validation = random.sample(array_range_over_lighting_validation, img_per_class_val_test)\n",
    "    array_under_lighting_validation = random.sample(array_range_under_lighting_validation, img_per_class_val_test)\n",
    "    array_good_alignment_validation = random.sample(array_range_good_alignment_validation, img_per_class_val_test)\n",
    "\n",
    "\n",
    "    for i,row in enumerate(camera_alignment_reader):\n",
    "        if i in array_camera_alignment_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_camera_alignment_validation:\n",
    "            validation_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(obstructed_cameras_reader):\n",
    "        if i in array_obstructed_cameras_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_obstructed_cameras_validation:\n",
    "            validation_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(over_lighting_reader):\n",
    "        if i in array_over_lighting_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_over_lighting_validation:\n",
    "            validation_writer.writerow(row)\n",
    "    \n",
    "    for i,row in enumerate(under_lighting_reader):\n",
    "        if i in array_under_lighting_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_under_lighting_validation:\n",
    "            validation_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(good_alignment_reader):\n",
    "        if i in array_good_alignment_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_good_alignment_validation:\n",
    "            validation_writer.writerow(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificado para 3 classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/train_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/train_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/train_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/train_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "\n",
    "    row_count_camera_alignment = sum(1 for row in camera_alignment_reader)\n",
    "    row_count_obstructed_cameras = sum(1 for row in obstructed_cameras_reader)\n",
    "    row_count_over_lighting = sum(1 for row in over_lighting_reader)\n",
    "    row_count_under_lighting = sum(1 for row in under_lighting_reader)\n",
    "    row_count_lighting_issues = row_count_over_lighting + row_count_under_lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/split_1k_train_data_double.csv','a', newline='') as train_data_file, open('Quality/data/train_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/train_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/train_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/train_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "    img_per_class_train = 800\n",
    "\n",
    "    train_writer = csv.writer(train_data_file)\n",
    "\n",
    "    array_range_camera_alignment = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting = range(0, row_count_under_lighting)\n",
    "\n",
    "    array_camera_alignment = random.sample(array_range_camera_alignment, img_per_class_train)\n",
    "    array_obstructed_cameras = random.sample(array_range_obstructed_cameras, img_per_class_train)\n",
    "    array_over_lighting = random.sample(array_range_over_lighting, int(img_per_class_train/2))\n",
    "    array_under_lighting = random.sample(array_range_under_lighting, int(img_per_class_train/2))\n",
    "\n",
    "    for i,row in enumerate(camera_alignment_reader):\n",
    "        if i in array_camera_alignment:\n",
    "            train_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(obstructed_cameras_reader):\n",
    "        if i in array_obstructed_cameras:\n",
    "            train_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(over_lighting_reader):\n",
    "        if i in array_over_lighting:\n",
    "            train_writer.writerow(row)\n",
    "    \n",
    "    for i,row in enumerate(under_lighting_reader):\n",
    "        if i in array_under_lighting:\n",
    "            train_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/test_validation_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/test_validation_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/test_validation_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/test_validation_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file:\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "\n",
    "    row_count_camera_alignment = sum(1 for row in camera_alignment_reader)\n",
    "    row_count_obstructed_cameras = sum(1 for row in obstructed_cameras_reader)\n",
    "    row_count_over_lighting = sum(1 for row in over_lighting_reader)\n",
    "    row_count_under_lighting = sum(1 for row in under_lighting_reader)\n",
    "    row_count_lighting_issues = row_count_over_lighting + row_count_under_lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/split_1k_test_data_double.csv','a', newline='') as test_data_file, open('Quality/data/split_1k_validation_data_double.csv','a', newline='') as validation_data_file , open('Quality/data/test_validation_by_classes/1_Camera_alignment.csv', 'r') as camera_alignment_file, open('Quality/data/test_validation_by_classes/2_Obstructed_cameras.csv', 'r') as obstructed_cameras_file, open('Quality/data/test_validation_by_classes/3_Over_lighting.csv', 'r') as over_lighting_file, open('Quality/data/test_validation_by_classes/4_Under_lighting.csv', 'r') as under_lighting_file :\n",
    "    camera_alignment_reader = csv.reader(camera_alignment_file)\n",
    "    obstructed_cameras_reader = csv.reader(obstructed_cameras_file)\n",
    "    over_lighting_reader = csv.reader(over_lighting_file)\n",
    "    under_lighting_reader = csv.reader(under_lighting_file)\n",
    "\n",
    "    img_per_class_val_test = 120\n",
    "\n",
    "    test_writer = csv.writer(test_data_file)\n",
    "    validation_writer = csv.writer(validation_data_file)\n",
    "\n",
    "    array_range_camera_alignment_test = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras_test = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting_test = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting_test = range(0, row_count_under_lighting)\n",
    "    \n",
    "    array_camera_alignment_test = random.sample(array_range_camera_alignment_test, img_per_class_val_test)\n",
    "    array_obstructed_cameras_test = random.sample(array_range_obstructed_cameras_test, img_per_class_val_test)\n",
    "    array_over_lighting_test = random.sample(array_range_over_lighting_test, int(img_per_class_val_test/2))\n",
    "    array_under_lighting_test = random.sample(array_range_under_lighting_test, int(img_per_class_val_test/2))\n",
    "\n",
    "    array_range_camera_alignment_validation = range(0,row_count_camera_alignment)\n",
    "    array_range_obstructed_cameras_validation = range(0,row_count_obstructed_cameras)\n",
    "    array_range_over_lighting_validation = range(0,row_count_over_lighting)\n",
    "    array_range_under_lighting_validation = range(0, row_count_under_lighting)\n",
    "    \n",
    "    array_camera_alignment_validation = random.sample(array_range_camera_alignment_validation, img_per_class_val_test)\n",
    "    array_obstructed_cameras_validation = random.sample(array_range_obstructed_cameras_validation, img_per_class_val_test)\n",
    "    array_over_lighting_validation = random.sample(array_range_over_lighting_validation, int(img_per_class_val_test/2))\n",
    "    array_under_lighting_validation = random.sample(array_range_under_lighting_validation, int(img_per_class_val_test/2))\n",
    "\n",
    "\n",
    "    for i,row in enumerate(camera_alignment_reader):\n",
    "        if i in array_camera_alignment_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_camera_alignment_validation:\n",
    "            validation_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(obstructed_cameras_reader):\n",
    "        if i in array_obstructed_cameras_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_obstructed_cameras_validation:\n",
    "            validation_writer.writerow(row)\n",
    "\n",
    "    for i,row in enumerate(over_lighting_reader):\n",
    "        if i in array_over_lighting_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_over_lighting_validation:\n",
    "            validation_writer.writerow(row)\n",
    "    \n",
    "    for i,row in enumerate(under_lighting_reader):\n",
    "        if i in array_under_lighting_test:\n",
    "            test_writer.writerow(row)\n",
    "        if i in array_under_lighting_validation:\n",
    "            validation_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visibility_frames\\Video_10_Poor does not exist, creating one...\n",
      "['Visibility\\\\Video_10_Poor\\\\20210329114717566@Block209F_HD1_PORT.mp4', 'Visibility\\\\Video_10_Poor\\\\20210329114717590@Block209F_HD2_CENTRE.mp4', 'Visibility\\\\Video_10_Poor\\\\20210329114717609@Block209F_HD3_STBD.mp4']\n",
      "Frame:0 | Success:True\n",
      "Frame:500 | Success:True\n",
      "Frame:1000 | Success:True\n",
      "Frame:1500 | Success:True\n",
      "Frame:2000 | Success:True\n",
      "Frame:2500 | Success:True\n",
      "Frame:3000 | Success:True\n",
      "Frame:3500 | Success:True\n",
      "Frame:4000 | Success:True\n",
      "Frame:4500 | Success:True\n",
      "Frame:5000 | Success:True\n",
      "Frame:5500 | Success:True\n",
      "Frame:6000 | Success:True\n",
      "Frame:6500 | Success:True\n",
      "Frame:7000 | Success:True\n",
      "Frame:7500 | Success:True\n",
      "Frame:8000 | Success:True\n",
      "Frame:8500 | Success:True\n",
      "Frame:9000 | Success:True\n",
      "Frame:9500 | Success:True\n",
      "Frame:10000 | Success:True\n",
      "Frame:10500 | Success:True\n",
      "Frame:11000 | Success:True\n",
      "Frame:11500 | Success:True\n",
      "Frame:12000 | Success:True\n",
      "Frame:12500 | Success:True\n",
      "Frame:13000 | Success:True\n",
      "Frame:13500 | Success:True\n",
      "Frame:14000 | Success:True\n",
      "Frame:14500 | Success:True\n",
      "Frame:15000 | Success:True\n",
      "Frame:15500 | Success:True\n",
      "Frame:16000 | Success:True\n",
      "Frame:16500 | Success:True\n",
      "Frame:17000 | Success:True\n",
      "Frame:17500 | Success:True\n",
      "Frame:18000 | Success:True\n",
      "Frame:18500 | Success:True\n",
      "Frame:19000 | Success:True\n",
      "Frame:19500 | Success:True\n",
      "Frame:20000 | Success:True\n",
      "Frame:20500 | Success:True\n",
      "Frame:21000 | Success:True\n",
      "Frame:21500 | Success:True\n",
      "Frame:22000 | Success:True\n",
      "Frame:22500 | Success:True\n",
      "Frame:23000 | Success:True\n",
      "Frame:23500 | Success:True\n",
      "Frame:24000 | Success:True\n",
      "Frame:24500 | Success:True\n",
      "Frame:25000 | Success:True\n",
      "Frame:25500 | Success:True\n",
      "Frame:26000 | Success:True\n",
      "Frame:26500 | Success:True\n",
      "Frame:27000 | Success:True\n",
      "Frame:27500 | Success:True\n",
      "Frame:28000 | Success:True\n",
      "Frame:28500 | Success:True\n",
      "Frame:29000 | Success:True\n",
      "Frame:29500 | Success:True\n",
      "Frame:30000 | Success:True\n",
      "Frame:30500 | Success:True\n",
      "Frame:31000 | Success:True\n",
      "Frame:31500 | Success:True\n",
      "Frame:32000 | Success:True\n",
      "Frame:32500 | Success:True\n",
      "Frame:33000 | Success:True\n",
      "Frame:0 | Success:True\n",
      "Frame:500 | Success:True\n",
      "Frame:1000 | Success:True\n",
      "Frame:1500 | Success:True\n",
      "Frame:2000 | Success:True\n",
      "Frame:2500 | Success:True\n",
      "Frame:3000 | Success:True\n",
      "Frame:3500 | Success:True\n",
      "Frame:4000 | Success:True\n",
      "Frame:4500 | Success:True\n",
      "Frame:5000 | Success:True\n",
      "Frame:5500 | Success:True\n",
      "Frame:6000 | Success:True\n",
      "Frame:6500 | Success:True\n",
      "Frame:7000 | Success:True\n",
      "Frame:7500 | Success:True\n",
      "Frame:8000 | Success:True\n",
      "Frame:8500 | Success:True\n",
      "Frame:9000 | Success:True\n",
      "Frame:9500 | Success:True\n",
      "Frame:10000 | Success:True\n",
      "Frame:10500 | Success:True\n",
      "Frame:11000 | Success:True\n",
      "Frame:11500 | Success:True\n",
      "Frame:12000 | Success:True\n",
      "Frame:12500 | Success:True\n",
      "Frame:13000 | Success:True\n",
      "Frame:13500 | Success:True\n",
      "Frame:14000 | Success:True\n",
      "Frame:14500 | Success:True\n",
      "Frame:15000 | Success:True\n",
      "Frame:15500 | Success:True\n",
      "Frame:16000 | Success:True\n",
      "Frame:16500 | Success:True\n",
      "Frame:17000 | Success:True\n",
      "Frame:17500 | Success:True\n",
      "Frame:18000 | Success:True\n",
      "Frame:18500 | Success:True\n",
      "Frame:19000 | Success:True\n",
      "Frame:19500 | Success:True\n",
      "Frame:20000 | Success:True\n",
      "Frame:20500 | Success:True\n",
      "Frame:21000 | Success:True\n",
      "Frame:21500 | Success:True\n",
      "Frame:22000 | Success:True\n",
      "Frame:22500 | Success:True\n",
      "Frame:23000 | Success:True\n",
      "Frame:23500 | Success:True\n",
      "Frame:24000 | Success:True\n",
      "Frame:24500 | Success:True\n",
      "Frame:25000 | Success:True\n",
      "Frame:25500 | Success:True\n",
      "Frame:26000 | Success:True\n",
      "Frame:26500 | Success:True\n",
      "Frame:27000 | Success:True\n",
      "Frame:27500 | Success:True\n",
      "Frame:28000 | Success:True\n",
      "Frame:28500 | Success:True\n"
     ]
    }
   ],
   "source": [
    "#Change disk directory\n",
    "base_path = Path(\"E:/Users/joaor/NSP/2021\")\n",
    "if(Path().cwd() != Path(r\"E:\\Users\\joaor\\NSP\\2021\")):\n",
    "    os.chdir(base_path)\n",
    "\n",
    "video_name = \"Video_10_Poor\"\n",
    "\n",
    "videos_folder = Path(\"Visibility/\" + video_name)\n",
    "videos = glob.glob(str(videos_folder) + \"/*.mp4\")\n",
    "\n",
    "save_folder = Path(\"Visibility_frames/\"+video_name)\n",
    "check_dir(save_folder)\n",
    "save_folder = str(save_folder / video_name)\n",
    "\n",
    "print(videos)\n",
    "\n",
    "for i,video in enumerate(videos):\n",
    "    convert_mp4_to_png(video  ,save_folder+\"_\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "change_to_disk()\n",
    "\n",
    "imgs = glob.glob(\"Quality/dataset/Good_alignment/*.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in imgs:\n",
    "    row=[]\n",
    "    with  open('Quality/data/new_data/train_by_classes/5_Good_Alignment.csv','a', newline='') as good_alignment_csv:\n",
    "        writer = csv.writer(good_alignment_csv)\n",
    "        row.append(img[31:-4]) \n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quality/data/new_data/5_Good_Alignment.csv','r', newline='') as good_alignment_csv, open('Quality/data/new_data/train_by_classes/5_Good_Alignment.csv','a', newline='') as good_alignment_train, open('Quality/data/new_data/test_validation_by_classes/5_Good_Alignment.csv','a', newline='') as good_alignment_test:\n",
    "    reader = csv.reader(good_alignment_csv)\n",
    "\n",
    "    writer_train = csv.writer(good_alignment_train)\n",
    "    writer_test = csv.writer(good_alignment_test)\n",
    "\n",
    "    for row in reader:\n",
    "        if row[0].startswith(\"Video_32\"):\n",
    "            writer_test.writerow(row)\n",
    "        elif row[0].startswith(\"Vis_good\"):\n",
    "            writer_train.writerow(row)\n",
    "        elif row[0].startswith(\"Vis_Vgood\"):\n",
    "            writer_train.writerow(row)\n",
    "        # elif row[0].startswith(\"Video_18_*_frame5[0-9][0-9][0-9][0-9]\"):\n",
    "        #     writer_train.writerow(row)\n",
    "        # elif row[0].startswith(\"Video_18_*_frame5[0-9][0-9][0-9]\"):\n",
    "        #     writer_test.writerow(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15b211d7ad94b52292045efb4f8f9084eab8b035832c108b93ce5f33d27f5980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
