{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from dataloaders import *\n",
    "from data_preparation import *\n",
    "from allResNets import *\n",
    "from VGGs import *\n",
    "from MobileNetV3 import *\n",
    "from engine import *\n",
    "from efficientNet import *\n",
    "\n",
    "change_to_disk()\n",
    "data_dir = Path(\"clean_split_1k/\")\n",
    "models_path = Path('Models/')\n",
    "saves = Path('Trainning_results_saves/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    # Resize our images to 224x224\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    \n",
    "    # Rotate the images randomly (just to make it as independent from the position of the pipeline)\n",
    "    transforms.RandomRotation(180),\n",
    "\n",
    "    # Random crop\n",
    "    transforms.RandomCrop(140),\n",
    "\n",
    "    #Random horizontal flip\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # Normalize\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dl, validation_dl, test_dl, train_data, validation_data, test_data, class_names = create_dataloaders(data_dir, data_transform, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to play with\n",
    "# Hyperparameters -> NUM_EPOCHS - 100 | Learning_rate - 0.001 \n",
    "# Functions -> Optimizer - Rprop | Loss Function - Cross Entropy Loss\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "lr = 0.001\n",
    "device = get_device()\n",
    "\n",
    "effnetb0 = EfficientNetB0()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb1e59b4fbb4226a7a53b35dd53cda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0096 | train_acc: 0.5195 | validation_loss: 1.0732 | validation_acc: 0.6449\n",
      "Epoch: 2 | train_loss: 0.7030 | train_acc: 0.6723 | validation_loss: 0.6174 | validation_acc: 0.6965\n",
      "Epoch: 3 | train_loss: 0.6273 | train_acc: 0.7133 | validation_loss: 0.6223 | validation_acc: 0.6309\n",
      "Epoch: 4 | train_loss: 0.5761 | train_acc: 0.7282 | validation_loss: 0.9586 | validation_acc: 0.5664\n",
      "Epoch: 5 | train_loss: 0.5246 | train_acc: 0.7550 | validation_loss: 0.5966 | validation_acc: 0.7254\n",
      "Epoch: 6 | train_loss: 0.5141 | train_acc: 0.7588 | validation_loss: 1.4469 | validation_acc: 0.5684\n",
      "Epoch: 7 | train_loss: 0.5427 | train_acc: 0.7635 | validation_loss: 0.5757 | validation_acc: 0.6805\n",
      "Epoch: 8 | train_loss: 0.4790 | train_acc: 0.7857 | validation_loss: 0.4704 | validation_acc: 0.7715\n",
      "Epoch: 9 | train_loss: 0.4695 | train_acc: 0.7810 | validation_loss: 1.4139 | validation_acc: 0.5742\n",
      "Epoch: 10 | train_loss: 0.4562 | train_acc: 0.7953 | validation_loss: 0.4312 | validation_acc: 0.8063\n",
      "Epoch: 11 | train_loss: 0.4283 | train_acc: 0.7935 | validation_loss: 0.9109 | validation_acc: 0.6035\n",
      "Epoch: 12 | train_loss: 0.4122 | train_acc: 0.8053 | validation_loss: 0.6212 | validation_acc: 0.6738\n",
      "Epoch: 13 | train_loss: 0.4362 | train_acc: 0.7943 | validation_loss: 0.4683 | validation_acc: 0.8051\n",
      "Epoch: 14 | train_loss: 0.4160 | train_acc: 0.8040 | validation_loss: 0.4655 | validation_acc: 0.8051\n",
      "Epoch: 15 | train_loss: 0.3975 | train_acc: 0.8123 | validation_loss: 0.5124 | validation_acc: 0.7934\n",
      "Epoch: 16 | train_loss: 0.3928 | train_acc: 0.8190 | validation_loss: 0.4623 | validation_acc: 0.8219\n",
      "Epoch: 17 | train_loss: 0.3907 | train_acc: 0.8143 | validation_loss: 0.6263 | validation_acc: 0.6918\n",
      "Epoch: 18 | train_loss: 0.3814 | train_acc: 0.8240 | validation_loss: 0.4663 | validation_acc: 0.8137\n",
      "Epoch: 19 | train_loss: 0.3940 | train_acc: 0.8193 | validation_loss: 0.4326 | validation_acc: 0.8305\n",
      "Epoch: 20 | train_loss: 0.3782 | train_acc: 0.8313 | validation_loss: 0.4307 | validation_acc: 0.8215\n",
      "Epoch: 21 | train_loss: 0.3588 | train_acc: 0.8325 | validation_loss: 0.5918 | validation_acc: 0.7949\n",
      "Epoch: 22 | train_loss: 0.3381 | train_acc: 0.8452 | validation_loss: 0.4643 | validation_acc: 0.8168\n",
      "Epoch: 23 | train_loss: 0.3589 | train_acc: 0.8330 | validation_loss: 0.4455 | validation_acc: 0.8516\n",
      "Epoch: 24 | train_loss: 0.3442 | train_acc: 0.8413 | validation_loss: 0.4464 | validation_acc: 0.8242\n",
      "Epoch: 25 | train_loss: 0.3556 | train_acc: 0.8365 | validation_loss: 0.4508 | validation_acc: 0.8109\n",
      "Epoch: 26 | train_loss: 0.3360 | train_acc: 0.8470 | validation_loss: 0.4196 | validation_acc: 0.8531\n",
      "Epoch: 27 | train_loss: 0.3288 | train_acc: 0.8500 | validation_loss: 0.4578 | validation_acc: 0.8090\n",
      "Epoch: 28 | train_loss: 0.3276 | train_acc: 0.8470 | validation_loss: 0.4728 | validation_acc: 0.7953\n",
      "Epoch: 29 | train_loss: 0.3181 | train_acc: 0.8550 | validation_loss: 0.5006 | validation_acc: 0.7828\n",
      "Epoch: 30 | train_loss: 0.3231 | train_acc: 0.8552 | validation_loss: 0.6008 | validation_acc: 0.7895\n",
      "Epoch: 31 | train_loss: 0.3178 | train_acc: 0.8525 | validation_loss: 0.6177 | validation_acc: 0.7898\n",
      "Epoch: 32 | train_loss: 0.2990 | train_acc: 0.8608 | validation_loss: 0.3749 | validation_acc: 0.8473\n",
      "Epoch: 33 | train_loss: 0.3050 | train_acc: 0.8548 | validation_loss: 0.4474 | validation_acc: 0.8484\n",
      "Epoch: 34 | train_loss: 0.3154 | train_acc: 0.8572 | validation_loss: 0.5769 | validation_acc: 0.8086\n",
      "Epoch: 35 | train_loss: 0.2832 | train_acc: 0.8688 | validation_loss: 0.5758 | validation_acc: 0.8063\n",
      "Epoch: 36 | train_loss: 0.2996 | train_acc: 0.8672 | validation_loss: 0.5537 | validation_acc: 0.7996\n",
      "Epoch: 37 | train_loss: 0.2989 | train_acc: 0.8680 | validation_loss: 0.4813 | validation_acc: 0.8383\n",
      "Epoch: 38 | train_loss: 0.2770 | train_acc: 0.8678 | validation_loss: 0.6981 | validation_acc: 0.7891\n",
      "Epoch: 39 | train_loss: 0.2887 | train_acc: 0.8702 | validation_loss: 0.4793 | validation_acc: 0.8211\n",
      "Epoch: 40 | train_loss: 0.2759 | train_acc: 0.8708 | validation_loss: 0.5841 | validation_acc: 0.7957\n",
      "Epoch: 41 | train_loss: 0.2833 | train_acc: 0.8798 | validation_loss: 0.5021 | validation_acc: 0.8313\n",
      "Epoch: 42 | train_loss: 0.2767 | train_acc: 0.8728 | validation_loss: 0.5553 | validation_acc: 0.8164\n",
      "Epoch: 43 | train_loss: 0.2735 | train_acc: 0.8775 | validation_loss: 0.4730 | validation_acc: 0.8105\n",
      "Epoch: 44 | train_loss: 0.2676 | train_acc: 0.8800 | validation_loss: 0.6139 | validation_acc: 0.8309\n",
      "Epoch: 45 | train_loss: 0.2713 | train_acc: 0.8768 | validation_loss: 0.5241 | validation_acc: 0.8000\n",
      "Epoch: 46 | train_loss: 0.2733 | train_acc: 0.8755 | validation_loss: 0.4147 | validation_acc: 0.8484\n",
      "Epoch: 47 | train_loss: 0.2663 | train_acc: 0.8795 | validation_loss: 0.6986 | validation_acc: 0.7902\n",
      "Epoch: 48 | train_loss: 0.2543 | train_acc: 0.8815 | validation_loss: 0.5255 | validation_acc: 0.8176\n",
      "Epoch: 49 | train_loss: 0.2697 | train_acc: 0.8812 | validation_loss: 0.6106 | validation_acc: 0.7891\n",
      "Epoch: 50 | train_loss: 0.2511 | train_acc: 0.8848 | validation_loss: 0.5110 | validation_acc: 0.8402\n",
      "Epoch: 51 | train_loss: 0.2587 | train_acc: 0.8878 | validation_loss: 0.5612 | validation_acc: 0.7980\n",
      "Epoch: 52 | train_loss: 0.3360 | train_acc: 0.8598 | validation_loss: 0.8916 | validation_acc: 0.7371\n",
      "Epoch: 53 | train_loss: 0.3119 | train_acc: 0.8695 | validation_loss: 0.7707 | validation_acc: 0.7246\n",
      "Epoch: 54 | train_loss: 0.2698 | train_acc: 0.8822 | validation_loss: 0.5196 | validation_acc: 0.8469\n",
      "Epoch: 55 | train_loss: 0.2731 | train_acc: 0.8788 | validation_loss: 0.5549 | validation_acc: 0.8031\n",
      "Epoch: 56 | train_loss: 0.2473 | train_acc: 0.8865 | validation_loss: 0.5398 | validation_acc: 0.8414\n",
      "Epoch: 57 | train_loss: 0.2624 | train_acc: 0.8850 | validation_loss: 0.5973 | validation_acc: 0.8016\n",
      "Epoch: 58 | train_loss: 0.2438 | train_acc: 0.8938 | validation_loss: 0.4941 | validation_acc: 0.8098\n",
      "Epoch: 59 | train_loss: 0.2382 | train_acc: 0.8952 | validation_loss: 0.5125 | validation_acc: 0.8000\n",
      "Epoch: 60 | train_loss: 0.2533 | train_acc: 0.8895 | validation_loss: 0.6191 | validation_acc: 0.7695\n",
      "Epoch: 61 | train_loss: 0.2554 | train_acc: 0.8862 | validation_loss: 0.5494 | validation_acc: 0.8367\n",
      "Epoch: 62 | train_loss: 0.2683 | train_acc: 0.8822 | validation_loss: 0.4530 | validation_acc: 0.8266\n",
      "Epoch: 63 | train_loss: 0.2445 | train_acc: 0.8938 | validation_loss: 0.5168 | validation_acc: 0.8398\n",
      "Epoch: 64 | train_loss: 0.2539 | train_acc: 0.8895 | validation_loss: 0.4283 | validation_acc: 0.8551\n",
      "Epoch: 65 | train_loss: 0.2415 | train_acc: 0.8900 | validation_loss: 0.6228 | validation_acc: 0.7871\n",
      "Epoch: 66 | train_loss: 0.2369 | train_acc: 0.8948 | validation_loss: 0.4905 | validation_acc: 0.8551\n",
      "Epoch: 67 | train_loss: 0.2371 | train_acc: 0.8995 | validation_loss: 0.4648 | validation_acc: 0.8520\n",
      "Epoch: 68 | train_loss: 0.2356 | train_acc: 0.8968 | validation_loss: 0.3627 | validation_acc: 0.8867\n",
      "Epoch: 69 | train_loss: 0.2349 | train_acc: 0.8988 | validation_loss: 0.5747 | validation_acc: 0.8219\n",
      "Epoch: 70 | train_loss: 0.2615 | train_acc: 0.8838 | validation_loss: 0.5482 | validation_acc: 0.8160\n",
      "Epoch: 71 | train_loss: 0.2851 | train_acc: 0.8758 | validation_loss: 0.4731 | validation_acc: 0.8230\n",
      "Epoch: 72 | train_loss: 0.2522 | train_acc: 0.8868 | validation_loss: 1.6351 | validation_acc: 0.6020\n",
      "Epoch: 73 | train_loss: 0.3717 | train_acc: 0.8452 | validation_loss: 0.4498 | validation_acc: 0.8484\n",
      "Epoch: 74 | train_loss: 0.2874 | train_acc: 0.8668 | validation_loss: 0.3741 | validation_acc: 0.8695\n",
      "Epoch: 75 | train_loss: 0.2442 | train_acc: 0.8930 | validation_loss: 0.7068 | validation_acc: 0.7848\n",
      "Epoch: 76 | train_loss: 0.2602 | train_acc: 0.8872 | validation_loss: 0.6332 | validation_acc: 0.8207\n",
      "Epoch: 77 | train_loss: 0.2245 | train_acc: 0.9022 | validation_loss: 0.6448 | validation_acc: 0.7887\n",
      "Epoch: 78 | train_loss: 0.2399 | train_acc: 0.8942 | validation_loss: 0.6351 | validation_acc: 0.7918\n",
      "Epoch: 79 | train_loss: 0.2361 | train_acc: 0.8982 | validation_loss: 0.4391 | validation_acc: 0.8633\n",
      "Epoch: 80 | train_loss: 0.2289 | train_acc: 0.9008 | validation_loss: 0.4438 | validation_acc: 0.8621\n",
      "Epoch: 81 | train_loss: 0.2324 | train_acc: 0.8968 | validation_loss: 0.3680 | validation_acc: 0.8617\n",
      "Epoch: 82 | train_loss: 0.2247 | train_acc: 0.9018 | validation_loss: 0.3918 | validation_acc: 0.8551\n",
      "Epoch: 83 | train_loss: 0.2202 | train_acc: 0.9022 | validation_loss: 0.6101 | validation_acc: 0.8137\n",
      "Epoch: 84 | train_loss: 0.2265 | train_acc: 0.8992 | validation_loss: 0.6412 | validation_acc: 0.8195\n",
      "Epoch: 85 | train_loss: 0.2185 | train_acc: 0.9025 | validation_loss: 0.7153 | validation_acc: 0.7660\n",
      "Epoch: 86 | train_loss: 0.2217 | train_acc: 0.8995 | validation_loss: 0.6741 | validation_acc: 0.8332\n",
      "Epoch: 87 | train_loss: 0.2138 | train_acc: 0.9067 | validation_loss: 0.4222 | validation_acc: 0.8539\n",
      "Epoch: 88 | train_loss: 0.2376 | train_acc: 0.8982 | validation_loss: 0.5081 | validation_acc: 0.8562\n",
      "Epoch: 89 | train_loss: 0.2287 | train_acc: 0.9018 | validation_loss: 0.5034 | validation_acc: 0.8648\n",
      "Epoch: 90 | train_loss: 0.2205 | train_acc: 0.9042 | validation_loss: 0.5968 | validation_acc: 0.8555\n",
      "Epoch: 91 | train_loss: 0.2152 | train_acc: 0.9067 | validation_loss: 0.4620 | validation_acc: 0.8688\n",
      "Epoch: 92 | train_loss: 0.2379 | train_acc: 0.8960 | validation_loss: 0.7006 | validation_acc: 0.7691\n",
      "Epoch: 93 | train_loss: 0.2354 | train_acc: 0.9030 | validation_loss: 0.4888 | validation_acc: 0.8551\n",
      "Epoch: 94 | train_loss: 0.2212 | train_acc: 0.9018 | validation_loss: 0.4848 | validation_acc: 0.8762\n",
      "Epoch: 95 | train_loss: 0.2828 | train_acc: 0.8835 | validation_loss: 0.5050 | validation_acc: 0.8250\n",
      "Epoch: 96 | train_loss: 0.2206 | train_acc: 0.9070 | validation_loss: 0.4901 | validation_acc: 0.8484\n",
      "Epoch: 97 | train_loss: 0.2102 | train_acc: 0.9083 | validation_loss: 0.5772 | validation_acc: 0.8430\n",
      "Epoch: 98 | train_loss: 0.2172 | train_acc: 0.9065 | validation_loss: 0.4002 | validation_acc: 0.8695\n",
      "Epoch: 99 | train_loss: 0.2299 | train_acc: 0.9022 | validation_loss: 0.5013 | validation_acc: 0.8371\n",
      "Epoch: 100 | train_loss: 0.2195 | train_acc: 0.9067 | validation_loss: 0.9043 | validation_acc: 0.7109\n"
     ]
    }
   ],
   "source": [
    "#Train EfficientNetV3 B0\n",
    "effnetb0.to(device)\n",
    "nadam_optim = torch.optim.NAdam(params=effnetb0.parameters(), lr=lr)\n",
    "train_effnetb0_results, train_time_effnetb0 = train(effnetb0, train_dl, validation_dl, optimizer=nadam_optim, loss_fn=loss_fn, epochs=NUM_EPOCHS, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67f1a1ed4034cc1878044f2576db084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_effnetb0_results = eval_model(effnetb0, test_dl, loss_fn = loss_fn, accuracy_fn=accuracy_fn, device = device, dummy_input= torch.rand(32,3,224,224).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75aed916528248379f3ca64c24a97c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.3187 | train_acc: 0.3937 | validation_loss: 0.9301 | validation_acc: 0.5938\n",
      "Epoch: 2 | train_loss: 0.9595 | train_acc: 0.5485 | validation_loss: 0.9436 | validation_acc: 0.5285\n",
      "Epoch: 3 | train_loss: 0.8385 | train_acc: 0.6092 | validation_loss: 0.8765 | validation_acc: 0.5758\n",
      "Epoch: 4 | train_loss: 0.8406 | train_acc: 0.6310 | validation_loss: 0.7315 | validation_acc: 0.6945\n",
      "Epoch: 5 | train_loss: 0.8247 | train_acc: 0.6235 | validation_loss: 0.6734 | validation_acc: 0.6660\n",
      "Epoch: 6 | train_loss: 0.7423 | train_acc: 0.6528 | validation_loss: 0.6408 | validation_acc: 0.6777\n",
      "Epoch: 7 | train_loss: 0.7500 | train_acc: 0.6545 | validation_loss: 0.8845 | validation_acc: 0.6016\n",
      "Epoch: 8 | train_loss: 0.7821 | train_acc: 0.6500 | validation_loss: 0.6139 | validation_acc: 0.7180\n",
      "Epoch: 9 | train_loss: 0.6898 | train_acc: 0.6743 | validation_loss: 8.2936 | validation_acc: 0.3789\n",
      "Epoch: 10 | train_loss: 0.6660 | train_acc: 0.6967 | validation_loss: 0.6022 | validation_acc: 0.7348\n",
      "Epoch: 11 | train_loss: 0.6364 | train_acc: 0.7095 | validation_loss: 0.5970 | validation_acc: 0.7289\n",
      "Epoch: 12 | train_loss: 0.6214 | train_acc: 0.7063 | validation_loss: 0.5487 | validation_acc: 0.7582\n",
      "Epoch: 13 | train_loss: 0.6060 | train_acc: 0.7170 | validation_loss: 0.5961 | validation_acc: 0.7430\n",
      "Epoch: 14 | train_loss: 0.6171 | train_acc: 0.7133 | validation_loss: 0.5964 | validation_acc: 0.7430\n",
      "Epoch: 15 | train_loss: 0.5724 | train_acc: 0.7388 | validation_loss: 0.6812 | validation_acc: 0.6746\n",
      "Epoch: 16 | train_loss: 0.5708 | train_acc: 0.7312 | validation_loss: 0.5642 | validation_acc: 0.7281\n",
      "Epoch: 17 | train_loss: 0.5514 | train_acc: 0.7480 | validation_loss: 0.5434 | validation_acc: 0.7844\n",
      "Epoch: 18 | train_loss: 0.5496 | train_acc: 0.7362 | validation_loss: 0.5421 | validation_acc: 0.7605\n",
      "Epoch: 19 | train_loss: 0.5421 | train_acc: 0.7512 | validation_loss: 0.6169 | validation_acc: 0.7215\n",
      "Epoch: 20 | train_loss: 0.5648 | train_acc: 0.7442 | validation_loss: 0.5673 | validation_acc: 0.7547\n",
      "Epoch: 21 | train_loss: 0.5267 | train_acc: 0.7550 | validation_loss: 0.5346 | validation_acc: 0.7750\n",
      "Epoch: 22 | train_loss: 0.5115 | train_acc: 0.7608 | validation_loss: 0.6013 | validation_acc: 0.7148\n",
      "Epoch: 23 | train_loss: 0.4825 | train_acc: 0.7688 | validation_loss: 0.5278 | validation_acc: 0.7926\n",
      "Epoch: 24 | train_loss: 0.4679 | train_acc: 0.7833 | validation_loss: 0.5205 | validation_acc: 0.7676\n",
      "Epoch: 25 | train_loss: 0.4566 | train_acc: 0.7935 | validation_loss: 0.5104 | validation_acc: 0.8230\n",
      "Epoch: 26 | train_loss: 0.4536 | train_acc: 0.7903 | validation_loss: 0.4458 | validation_acc: 0.8008\n",
      "Epoch: 27 | train_loss: 0.4562 | train_acc: 0.7833 | validation_loss: 0.5661 | validation_acc: 0.6855\n",
      "Epoch: 28 | train_loss: 0.5888 | train_acc: 0.7325 | validation_loss: 0.5895 | validation_acc: 0.7461\n",
      "Epoch: 29 | train_loss: 0.5436 | train_acc: 0.7328 | validation_loss: 0.5333 | validation_acc: 0.7613\n",
      "Epoch: 30 | train_loss: 0.4826 | train_acc: 0.7840 | validation_loss: 0.4400 | validation_acc: 0.7906\n",
      "Epoch: 31 | train_loss: 0.4875 | train_acc: 0.7665 | validation_loss: 0.5665 | validation_acc: 0.7633\n",
      "Epoch: 32 | train_loss: 0.4449 | train_acc: 0.7883 | validation_loss: 0.5360 | validation_acc: 0.8012\n",
      "Epoch: 33 | train_loss: 0.4216 | train_acc: 0.8043 | validation_loss: 0.5629 | validation_acc: 0.7781\n",
      "Epoch: 34 | train_loss: 0.4272 | train_acc: 0.7987 | validation_loss: 0.5325 | validation_acc: 0.7961\n",
      "Epoch: 35 | train_loss: 0.4791 | train_acc: 0.7788 | validation_loss: 0.6244 | validation_acc: 0.7082\n",
      "Epoch: 36 | train_loss: 0.5217 | train_acc: 0.7558 | validation_loss: 0.5238 | validation_acc: 0.7879\n",
      "Epoch: 37 | train_loss: 0.4529 | train_acc: 0.7840 | validation_loss: 0.5376 | validation_acc: 0.8047\n",
      "Epoch: 38 | train_loss: 0.4255 | train_acc: 0.7960 | validation_loss: 0.5926 | validation_acc: 0.7504\n",
      "Epoch: 39 | train_loss: 0.4197 | train_acc: 0.8015 | validation_loss: 0.4746 | validation_acc: 0.7914\n",
      "Epoch: 40 | train_loss: 0.4079 | train_acc: 0.8145 | validation_loss: 0.4983 | validation_acc: 0.7941\n",
      "Epoch: 41 | train_loss: 0.4178 | train_acc: 0.8165 | validation_loss: 0.5534 | validation_acc: 0.7937\n",
      "Epoch: 42 | train_loss: 0.3933 | train_acc: 0.8173 | validation_loss: 0.4880 | validation_acc: 0.8023\n",
      "Epoch: 43 | train_loss: 0.4017 | train_acc: 0.8185 | validation_loss: 0.5362 | validation_acc: 0.7832\n",
      "Epoch: 44 | train_loss: 0.3901 | train_acc: 0.8233 | validation_loss: 0.4504 | validation_acc: 0.8230\n",
      "Epoch: 45 | train_loss: 0.3774 | train_acc: 0.8267 | validation_loss: 0.4039 | validation_acc: 0.8457\n",
      "Epoch: 46 | train_loss: 0.3658 | train_acc: 0.8320 | validation_loss: 0.5592 | validation_acc: 0.7695\n",
      "Epoch: 47 | train_loss: 0.3655 | train_acc: 0.8300 | validation_loss: 0.4679 | validation_acc: 0.8168\n",
      "Epoch: 48 | train_loss: 0.3640 | train_acc: 0.8330 | validation_loss: 0.5345 | validation_acc: 0.8184\n",
      "Epoch: 49 | train_loss: 0.3832 | train_acc: 0.8200 | validation_loss: 0.5340 | validation_acc: 0.7973\n",
      "Epoch: 50 | train_loss: 0.3737 | train_acc: 0.8283 | validation_loss: 0.4072 | validation_acc: 0.8457\n",
      "Epoch: 51 | train_loss: 0.3515 | train_acc: 0.8407 | validation_loss: 0.3958 | validation_acc: 0.8441\n",
      "Epoch: 52 | train_loss: 0.3544 | train_acc: 0.8417 | validation_loss: 0.4486 | validation_acc: 0.8129\n",
      "Epoch: 53 | train_loss: 0.4218 | train_acc: 0.8075 | validation_loss: 0.4747 | validation_acc: 0.7891\n",
      "Epoch: 54 | train_loss: 0.3816 | train_acc: 0.8240 | validation_loss: 0.5181 | validation_acc: 0.8133\n",
      "Epoch: 55 | train_loss: 0.3786 | train_acc: 0.8360 | validation_loss: 0.4799 | validation_acc: 0.8238\n",
      "Epoch: 56 | train_loss: 0.3629 | train_acc: 0.8390 | validation_loss: 0.4666 | validation_acc: 0.8184\n",
      "Epoch: 57 | train_loss: 0.3574 | train_acc: 0.8300 | validation_loss: 0.4677 | validation_acc: 0.8180\n",
      "Epoch: 58 | train_loss: 0.3560 | train_acc: 0.8373 | validation_loss: 0.4772 | validation_acc: 0.7871\n",
      "Epoch: 59 | train_loss: 0.3631 | train_acc: 0.8385 | validation_loss: 0.4494 | validation_acc: 0.8227\n",
      "Epoch: 60 | train_loss: 0.3723 | train_acc: 0.8387 | validation_loss: 0.4351 | validation_acc: 0.8277\n",
      "Epoch: 61 | train_loss: 0.3673 | train_acc: 0.8333 | validation_loss: 0.5484 | validation_acc: 0.7703\n",
      "Epoch: 62 | train_loss: 0.3291 | train_acc: 0.8525 | validation_loss: 0.5442 | validation_acc: 0.8094\n",
      "Epoch: 63 | train_loss: 0.3594 | train_acc: 0.8397 | validation_loss: 0.4614 | validation_acc: 0.8414\n",
      "Epoch: 64 | train_loss: 0.3683 | train_acc: 0.8333 | validation_loss: 0.4073 | validation_acc: 0.8488\n",
      "Epoch: 65 | train_loss: 0.3461 | train_acc: 0.8423 | validation_loss: 0.5039 | validation_acc: 0.8031\n",
      "Epoch: 66 | train_loss: 0.3278 | train_acc: 0.8528 | validation_loss: 0.4043 | validation_acc: 0.8574\n",
      "Epoch: 67 | train_loss: 0.3283 | train_acc: 0.8562 | validation_loss: 0.5081 | validation_acc: 0.8086\n",
      "Epoch: 68 | train_loss: 0.3453 | train_acc: 0.8482 | validation_loss: 0.4424 | validation_acc: 0.8234\n",
      "Epoch: 69 | train_loss: 0.3590 | train_acc: 0.8417 | validation_loss: 0.5856 | validation_acc: 0.7355\n",
      "Epoch: 70 | train_loss: 0.3490 | train_acc: 0.8365 | validation_loss: 0.4232 | validation_acc: 0.8379\n",
      "Epoch: 71 | train_loss: 0.3206 | train_acc: 0.8595 | validation_loss: 0.4805 | validation_acc: 0.8387\n",
      "Epoch: 72 | train_loss: 0.3095 | train_acc: 0.8610 | validation_loss: 0.5645 | validation_acc: 0.7988\n",
      "Epoch: 73 | train_loss: 0.3457 | train_acc: 0.8460 | validation_loss: 0.4993 | validation_acc: 0.7773\n",
      "Epoch: 74 | train_loss: 0.3247 | train_acc: 0.8518 | validation_loss: 0.7218 | validation_acc: 0.7434\n",
      "Epoch: 75 | train_loss: 0.3359 | train_acc: 0.8485 | validation_loss: 0.4740 | validation_acc: 0.8508\n",
      "Epoch: 76 | train_loss: 0.3204 | train_acc: 0.8548 | validation_loss: 0.5493 | validation_acc: 0.8254\n",
      "Epoch: 77 | train_loss: 0.3138 | train_acc: 0.8602 | validation_loss: 0.5305 | validation_acc: 0.7859\n",
      "Epoch: 78 | train_loss: 0.3178 | train_acc: 0.8528 | validation_loss: 0.4874 | validation_acc: 0.8230\n",
      "Epoch: 79 | train_loss: 0.3120 | train_acc: 0.8588 | validation_loss: 0.6560 | validation_acc: 0.7586\n",
      "Epoch: 80 | train_loss: 0.2988 | train_acc: 0.8678 | validation_loss: 0.6277 | validation_acc: 0.7883\n",
      "Epoch: 81 | train_loss: 0.3062 | train_acc: 0.8658 | validation_loss: 0.5388 | validation_acc: 0.7992\n",
      "Epoch: 82 | train_loss: 0.2953 | train_acc: 0.8625 | validation_loss: 0.5874 | validation_acc: 0.8063\n",
      "Epoch: 83 | train_loss: 0.2915 | train_acc: 0.8678 | validation_loss: 0.4268 | validation_acc: 0.8398\n",
      "Epoch: 84 | train_loss: 0.2879 | train_acc: 0.8702 | validation_loss: 0.4650 | validation_acc: 0.8363\n",
      "Epoch: 85 | train_loss: 0.2995 | train_acc: 0.8692 | validation_loss: 0.5976 | validation_acc: 0.8031\n",
      "Epoch: 86 | train_loss: 0.2947 | train_acc: 0.8615 | validation_loss: 0.7250 | validation_acc: 0.7016\n",
      "Epoch: 87 | train_loss: 0.2845 | train_acc: 0.8680 | validation_loss: 0.5301 | validation_acc: 0.8250\n",
      "Epoch: 88 | train_loss: 0.2782 | train_acc: 0.8718 | validation_loss: 0.6392 | validation_acc: 0.8055\n",
      "Epoch: 89 | train_loss: 0.2854 | train_acc: 0.8730 | validation_loss: 0.7750 | validation_acc: 0.7828\n",
      "Epoch: 90 | train_loss: 0.2987 | train_acc: 0.8688 | validation_loss: 0.4620 | validation_acc: 0.8516\n",
      "Epoch: 91 | train_loss: 0.2852 | train_acc: 0.8732 | validation_loss: 0.5257 | validation_acc: 0.8063\n",
      "Epoch: 92 | train_loss: 0.2797 | train_acc: 0.8732 | validation_loss: 0.6682 | validation_acc: 0.7902\n",
      "Epoch: 93 | train_loss: 0.2770 | train_acc: 0.8750 | validation_loss: 0.9904 | validation_acc: 0.7535\n",
      "Epoch: 94 | train_loss: 0.2841 | train_acc: 0.8735 | validation_loss: 0.6438 | validation_acc: 0.7668\n",
      "Epoch: 95 | train_loss: 0.2793 | train_acc: 0.8795 | validation_loss: 0.7512 | validation_acc: 0.7520\n",
      "Epoch: 96 | train_loss: 0.2738 | train_acc: 0.8780 | validation_loss: 0.7246 | validation_acc: 0.7727\n",
      "Epoch: 97 | train_loss: 0.2747 | train_acc: 0.8782 | validation_loss: 0.4054 | validation_acc: 0.8574\n",
      "Epoch: 98 | train_loss: 0.2751 | train_acc: 0.8800 | validation_loss: 0.5410 | validation_acc: 0.7965\n",
      "Epoch: 99 | train_loss: 0.2696 | train_acc: 0.8732 | validation_loss: 0.7897 | validation_acc: 0.7723\n",
      "Epoch: 100 | train_loss: 0.2827 | train_acc: 0.8755 | validation_loss: 0.6056 | validation_acc: 0.7996\n"
     ]
    }
   ],
   "source": [
    "effnetb5 = EfficientNetB5()\n",
    "#Train EfficientNetV3 B5\n",
    "effnetb5.to(device)\n",
    "nadam_optim = torch.optim.NAdam(params=effnetb5.parameters(), lr=lr)\n",
    "train_effnetb5_results, train_time_effnetb5 = train(effnetb5, train_dl, validation_dl, optimizer=nadam_optim, loss_fn=loss_fn, epochs=NUM_EPOCHS, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model to: Models\\effnetb0_100epc.pth\n",
      "Saving the model to: Models\\effnetb5_100epc.pth\n"
     ]
    }
   ],
   "source": [
    "model_name = Path(\"effnetb0_100epc.pth\")\n",
    "save_model(models_path,model_name,effnetb0)\n",
    "\n",
    "model_name = Path(\"effnetb5_100epc.pth\")\n",
    "save_model(models_path,model_name,effnetb5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (features): Sequential(\n",
       "    (0): CNNBlock(\n",
       "      (cnn): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (silu): SiLU()\n",
       "    )\n",
       "    (1): InvertedResidualBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(16, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(24, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(24, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(40, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(40, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(80, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(80, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(80, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(112, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(112, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(112, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(192, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(192, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(192, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(192, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): CNNBlock(\n",
       "      (cnn): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (silu): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = Path(\"effnetb0_100epc.pth\")\n",
    "model_path = models_path/model_name\n",
    "loaded_model_effnetb0 = EfficientNetB0()\n",
    "loaded_model_effnetb0.load_state_dict(torch.load(model_path))\n",
    "loaded_model_effnetb0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0f0af2198e4bf39891f43604c550e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_effnetb0_results = eval_model(loaded_model_effnetb0, test_dl, loss_fn = loss_fn, accuracy_fn=accuracy_fn, device = device, dummy_input= torch.rand(32,3,224,224).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (features): Sequential(\n",
       "    (0): CNNBlock(\n",
       "      (cnn): Conv2d(3, 46, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (silu): SiLU()\n",
       "    )\n",
       "    (1): InvertedResidualBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(46, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=46, bias=False)\n",
       "          (bn): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(46, 11, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(11, 46, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(46, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidualBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidualBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(24, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(36, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "          (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(216, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(9, 216, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(216, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(36, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "          (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(216, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(9, 216, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(216, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(36, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "          (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(216, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(9, 216, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(216, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(36, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)\n",
       "          (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(216, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(9, 216, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(216, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(36, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(216, 216, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=216, bias=False)\n",
       "          (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(216, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(9, 216, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(216, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(60, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360, bias=False)\n",
       "          (bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(360, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(15, 360, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(60, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360, bias=False)\n",
       "          (bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(360, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(15, 360, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(60, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360, bias=False)\n",
       "          (bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(360, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(15, 360, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(60, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360, bias=False)\n",
       "          (bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(360, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(15, 360, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(60, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(360, 360, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=360, bias=False)\n",
       "          (bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(360, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(15, 360, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(360, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(120, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=720, bias=False)\n",
       "          (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(120, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=720, bias=False)\n",
       "          (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(120, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=720, bias=False)\n",
       "          (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(120, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=720, bias=False)\n",
       "          (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (19): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(120, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=720, bias=False)\n",
       "          (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (20): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(120, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=720, bias=False)\n",
       "          (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (21): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(120, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "          (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(720, 164, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (22): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(164, 984, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(984, 984, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=984, bias=False)\n",
       "          (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(984, 41, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(41, 984, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(984, 164, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (23): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(164, 984, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(984, 984, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=984, bias=False)\n",
       "          (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(984, 41, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(41, 984, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(984, 164, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (24): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(164, 984, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(984, 984, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=984, bias=False)\n",
       "          (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(984, 41, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(41, 984, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(984, 164, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (25): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(164, 984, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(984, 984, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=984, bias=False)\n",
       "          (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(984, 41, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(41, 984, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(984, 164, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (26): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(164, 984, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(984, 984, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=984, bias=False)\n",
       "          (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(984, 41, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(41, 984, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(984, 164, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (27): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(164, 984, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(984, 984, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=984, bias=False)\n",
       "          (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(984, 41, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(41, 984, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(984, 164, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (28): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(164, 984, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(984, 984, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=984, bias=False)\n",
       "          (bn): BatchNorm2d(984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(984, 41, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(41, 984, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(984, 284, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(284, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (29): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(284, 1704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1704, 1704, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1704, bias=False)\n",
       "          (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1704, 71, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(71, 1704, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1704, 284, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(284, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (30): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(284, 1704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1704, 1704, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1704, bias=False)\n",
       "          (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1704, 71, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(71, 1704, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1704, 284, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(284, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (31): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(284, 1704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1704, 1704, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1704, bias=False)\n",
       "          (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1704, 71, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(71, 1704, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1704, 284, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(284, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (32): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(284, 1704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1704, 1704, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1704, bias=False)\n",
       "          (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1704, 71, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(71, 1704, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1704, 284, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(284, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (33): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(284, 1704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1704, 1704, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1704, bias=False)\n",
       "          (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1704, 71, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(71, 1704, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1704, 284, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(284, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (34): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(284, 1704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1704, 1704, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1704, bias=False)\n",
       "          (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1704, 71, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(71, 1704, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1704, 284, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(284, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (35): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(284, 1704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1704, 1704, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1704, bias=False)\n",
       "          (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1704, 71, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(71, 1704, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1704, 284, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(284, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (36): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(284, 1704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1704, 1704, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1704, bias=False)\n",
       "          (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1704, 71, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(71, 1704, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1704, 284, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(284, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (37): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(284, 1704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(1704, 1704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1704, bias=False)\n",
       "          (bn): BatchNorm2d(1704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(1704, 71, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(71, 1704, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(1704, 468, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(468, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (38): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(468, 2808, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(2808, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(2808, 2808, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2808, bias=False)\n",
       "          (bn): BatchNorm2d(2808, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(2808, 117, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(117, 2808, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(2808, 468, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(468, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (39): InvertedResidualBlock(\n",
       "      (expand_conv): CNNBlock(\n",
       "        (cnn): Conv2d(468, 2808, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(2808, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (silu): SiLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (cnn): Conv2d(2808, 2808, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2808, bias=False)\n",
       "          (bn): BatchNorm2d(2808, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(2808, 117, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): SiLU()\n",
       "            (3): Conv2d(117, 2808, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): Conv2d(2808, 468, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(468, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (40): CNNBlock(\n",
       "      (cnn): Conv2d(468, 1875, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(1875, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (silu): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.4, inplace=False)\n",
       "    (1): Linear(in_features=1875, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = Path(\"effnetb5_100epc.pth\")\n",
    "model_path = models_path/model_name\n",
    "loaded_model_effnetb5 = EfficientNetB5()\n",
    "loaded_model_effnetb5.load_state_dict(torch.load(model_path))\n",
    "loaded_model_effnetb5.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 8.00 GiB total capacity; 7.07 GiB already allocated; 0 bytes free; 7.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10992\\1900742932.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meval_effnetb5_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_model_effnetb5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccuracy_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\joaor\\Desktop\\AQAUIS\\AQAUIS\\Code\\utils.py\u001b[0m in \u001b[0;36meval_model\u001b[1;34m(model, data_loader, loss_fn, accuracy_fn, device, dummy_input)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m#GPU-WARM-UP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\Desktop\\AQAUIS\\AQAUIS\\Code\\efficientNet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\Desktop\\AQAUIS\\AQAUIS\\Code\\efficientNet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_residual\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\Desktop\\AQAUIS\\AQAUIS\\Code\\efficientNet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joaor\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 8.00 GiB total capacity; 7.07 GiB already allocated; 0 bytes free; 7.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "eval_effnetb5_results = eval_model(loaded_model_effnetb5, test_dl, loss_fn = loss_fn, accuracy_fn=accuracy_fn, device = device, dummy_input= torch.rand(32,3,224,224).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_effnetb0_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10992\\1977009521.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_loss_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_effnetb0_results\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"EfficientNet B0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_effnetb0_results' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss_curves(train_effnetb0_results,\"EfficientNet B0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(train_effnetb5_results,\"EfficientNet B5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(effnetb0,test_dl,device,class_names, \"EfficientNet B0\"), plot_confusion_matrix(effnetb5, test_dl, device, class_names, \"EfficientNet B5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.DataFrame([\n",
    "    eval_effnetb0_results,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "      <th>model_inf_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EfficientNet</td>\n",
       "      <td>7.698823</td>\n",
       "      <td>29.882812</td>\n",
       "      <td>66.912255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  model_loss  model_acc  model_inf_time\n",
       "0  EfficientNet    7.698823  29.882812       66.912255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
